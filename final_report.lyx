#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman lmodern
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 4cm
\topmargin 4.5cm
\rightmargin 4cm
\bottommargin 4.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Obtaining data
\end_layout

\begin_layout Standard
The first part of the project consisted of obtaining the required data to
 analyse players and their characteristics.
 A significant amount of historical data needed to be collected and as mentioned
 previously, 
\family typewriter
www.tennisinsight.com
\family default
 and 
\family typewriter
www.atpworldtour.com
\family default
 proved to be a very useful source of data, with all required match statistics
 and player profile information.
 Unfortunately, the website does not have an API that allowed us to easily
 retrieve the data, and it was obviously impractical to obtain the data
 manually.
 Hence, a web scraper was developed using Scrapy, a Python web scraping
 framework, to obtain the relevant statistics from these websites.
\end_layout

\begin_layout Subsection
Web scraper
\end_layout

\begin_layout Standard
The complete web scraper was made up of two separate scrapers, one to pull
 match statistics and one to retrieve the betting odds for a player to win
 the match.
 This was required because of the website's design, which had these two
 sets of information of different pages.
 TennisInsight identifies each player by a 'player id', which is used in
 the scraper as well.
 Both scrapers take this player id as an input to identify the corresponding
 tennis player and retrieve the player's data from his last 100 matches.
\end_layout

\begin_layout Subsubsection*
Match Statistics Scraper
\end_layout

\begin_layout Standard
This is the first component of the web scraper.
 The scraped pages each contain a list of all of a player's matches with
 corresponding links to more detailed match statistics (which are on either
 the ATP's website or TennisInsight).
 The scraper opens each of these links and retrieves the match statistics,
 saving them to a csv file.
 
\end_layout

\begin_layout Subsubsection*
Odds Scraper
\end_layout

\begin_layout Standard
A second scraper was needed because the match statistics and the odds were
 on separate pages.
 The odds for a player to win were scraped and these were merged with the
 match statistics collected previously to create a complete record.
 In addition, the dates for each of the matches played was on this page
 too, so the odds scraper retrieved this information as well.
\end_layout

\begin_layout Subsubsection*
Linking scraped records from both scrapers
\end_layout

\begin_layout Standard
After this data was collected separately by two different scrapers, it was
 important for them to be linked together to form complete records to simplify
 processing at later stages in the project.
 SQLite, a SQL database engine was used for this purpose, providing a quick
 and straightforward way to join tables using standard SQL commands.
\end_layout

\begin_layout Section
Developing a model
\end_layout

\begin_layout Standard
There are often similar aspects and styles between two tennis players.
 For example, there are players who rely on their serves to win a majority
 of their points, while there are other players who are not particularly
 strong servers, but win a relatively higher percentage of points when returning.
 In addition, there are some players who perform above the market expectations
 when they play on their preferred tennis court surface.
\end_layout

\begin_layout Standard
In this project, we aim to capture various types of players by analysing
 a range of match statistics and player information and use this data to
 build a model to help us get an indication of the eventual winner of a
 tennis match.
 In the general sense, we can use this information to find out whether,
 in a match up between two players, a certain player with a particular playing
 style has an advantage over another player with another playing style.
 We use clustering techniques over our match statistics and player profiles
 to identify these different playing styles, and to classify 'similar' players
 into specific clusters.
\end_layout

\begin_layout Subsection
Similar players
\end_layout

\begin_layout Standard
In this project, we introduce the idea of players with similar profiles
 in our model.
 We focus on two sets of attributes to identify similar players: general
 player profiles and past opponent profiles.
 In this section, we will first look at the attributes that belong to each
 set, and then proceed to how we can use clustering to group players into
 categories using these attributes.
\end_layout

\begin_layout Standard
For this project, we focus our analysis on the top 30 ranked players on
 the ATP tour as of May 20th 2014 [reference put rank list in appendix].
 [change why chosen the top 30 players] In addition, we have also included
 three other players in our analysis: Jeremy Chardy (ranked 40), Lleyton
 Hewitt (ranked 44), and Andreas Seppi (ranked 33), since these three players
 introduce interesting aspects into the project.
 For example, Lleyton Hewitt was ranked as world number 1 in 2001/02, but
 is currently 44, while Jeremy Chardy has caused some significant upsets
 over the past two years.
\end_layout

\begin_layout Subsubsection
General player profiles
\end_layout

\begin_layout Standard
The first set of attributes that we use to identify similar players include
 players' general statistics over the year leading up to the match that
 needs to be predicted.
 Data for this was retrieved from the TennisInsight website, which had profile
 pages on every tennis player.
 The attributes that we have included in the clustering are:
\end_layout

\begin_layout Enumerate
Surfaces (statistics include all matches over the past year)
\end_layout

\begin_deeper
\begin_layout Enumerate
Hard court win percentage
\end_layout

\begin_layout Enumerate
Clay court win percentage
\end_layout

\begin_layout Enumerate
Grass court win percentage
\end_layout

\end_deeper
\begin_layout Enumerate
Height
\end_layout

\begin_layout Enumerate
Age
\end_layout

\begin_layout Enumerate
Average net approaches (over previous 100 games where data is available)
\end_layout

\begin_layout Enumerate
Average first serve speed (over previous 100 games where data is available)
\end_layout

\begin_layout Enumerate
Service points won percentage (past year) across all opponents
\end_layout

\begin_layout Enumerate
Return points won percentage (past year) across all opponents
\end_layout

\begin_layout Enumerate
End of year ranking
\end_layout

\begin_layout Enumerate
Win percentage against the Top 20 ranked players (past year)
\end_layout

\begin_layout Standard
These statistics were collected for each player and fed into a CSV (Comma-separa
ted values) file, which is used to perform clustering over in section [section
 reference].
 As we will see in more detail later, clustering takes all these eleven
 statistics and groups players with similar statistics.
 Each cluster refers to a set of 'similar' players, which is what we try
 to achieve in this section.
\end_layout

\begin_layout Standard
It was an important decision to select the above attributes.
 A player's age was used because, as in any sport, it is a significant character
istic in classifying players, as this statistic is likely to give us an
 indication of a player's court speed.
 Height is considered to be a particularly important characteristic in tennis,
 especially for servers, as it makes a player's service harder to return
 because of the power, height, and bounce that is generated from a serve
 [reference to http://edition.cnn.com/2012/10/15/sport/tennis/tennis-nishikori-jap
an-size/index.html].
 In tennis, many players are seen to have their 'favorite' tennis court
 surface, and we introduce their win rate on the three different major surfaces
 to take this into account.
 We have included the average first serve speed and net approaches to classify
 players who rely largely on their service and their approaches to the net
 (also known as 
\begin_inset Quotes eld
\end_inset

serve and volley players
\begin_inset Quotes erd
\end_inset

).
 The service and return points won percentages are useful indicators of
 a player's overall performance across all their opponents.
 We describe the importance of these two statistics in the background section[se
ction reference].
 The final two statistics, win percentage against the top 20 and the end
 of year ranking, encompass a large variety of different attributes in one
 statistic, as described next in Limitations.
\end_layout

\begin_layout Subsubsection*
Limitations
\end_layout

\begin_layout Standard
It is a challenge to capture different playing styles of players through
 simply match statistics, especially due to the limitations of the data
 available.
 For example, we are able to retrieve information about a player's percentage
 of points won, and his preferred surface.
 However, more in-depth player information such as whether or not a player
 relies on a strong forehand, a player's court speed, or the degree of top-spin
 used in shots would certainly be beneficial for identifying more accurate
 playing styles.
 We aim to minimise the influence of this data limitation by including 'generic'
 attributes, such as the player's performance versus the Top 20 (for the
 previous year) or their end of year ranking, into the clustering analysis.
 'Generic' attributes encompass a player's performance over several games,
 and is likely to include certain factors that cannot be measured individually.
 For example, Rafael Nadal's has won 80% of his last ten matches against
 the Top 20 over the past year (as of June 8 2014), while Jerzy Janowicz
 has won 20%.
 This clearly tells us first that Nadal is the stronger player, winning
 a higher majority of his matches against a higher ranked opposition.
 However, this 80% value also serves as a statistic which measures Nadal's
 overall performance in these particular games, likely to be indicating
 his performance in specific (often unmeasurable) factors such as more accurate
 shots and a better tactical performance against the Top 20 players.
 
\end_layout

\begin_layout Subsubsection*
Normalising Statistics
\end_layout

\begin_layout Standard
The above attributes are presented in a wide range of units.
 For example, height is in centimetres, age is in years, and first serve
 speed is in kilometres per hour.
 Especially for clustering techniques used later on in the project, it is
 very integral that data is normalised and that there is no bias.
 Clustering techniques used later [section reference] make use of a distance
 measure, particularly the Euclidean distance, and if data was not rescaled
 or normalized, there would be significant biases in the clusters.
 The reason for this is that the clusters are influenced strongly by the
 magnitudes of the variables, especially in clustering techniques like k-means.
\end_layout

\begin_layout Standard
The formula used to rescale each attribute to the range [0,1] is presented
 in equation [equation reference].
 It is also known as feature scaling.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{new}=\frac{X-X_{min}}{X_{max}-X_{min}}
\]

\end_inset


\end_layout

\begin_layout Standard
The statistics that were normalised were height, age, average net approaches,
 end of year ranking, and average first serve speed.
 The other statistics are already percentages in the range of [0,1], so
 there is no need to rescale them.
 Since every attribute was in the same range, all attributes were given
 equal importance.
\end_layout

\begin_layout Subsubsection
Past opponent profiles
\end_layout

\begin_layout Standard
There is a significant limitation introduced if only general player profiles
 was used to classify similar players.
 The reason for this is that professional tennis players often approach
 their opponents in different ways, and not in the same way as statistics
 classify players.
 In addition, tennis players often perform better against a certain opponent
 A than another opponent B, even though both players A and B are similar
 statistically.
 This is why we also introduce 'past opponent profiles' to determine similar
 players.
 Essentially, this means that for a certain player, we look at the performances
 of each of his past opponents (in his last 100 matches) and group together
 opponents who perform similarly, in terms of service and return points
 won.
 Hence, the set of attributes used here to identify similar players includes
 just the percentage of service points won and the percentage of return
 points won.
\end_layout

\begin_layout Standard
Let us look at an example of the limitation introduced if solely the general
 player profiles were used to determine similar players, and how the concept
 of 'past opponent profiles' minimize this limitation.
 Roger Federer and Novak Djokovic are similar players in terms of general
 player profiles and statistics (both players have a consistent record against
 the top 20 players, have similar service and return points won percentages,
 and have similar heights and similar service speeds).
 However, let us look at these player's previous performances when playing
 current world number one Rafael Nadal.
 Roger Federer has lost each of his last five encounters against Nadal,
 while on the other hand, Novak Djokovic has won four out of his last five
 encounters with Nadal (statistics correct as of June 2014).
 This example gives us some indication that even though players might be
 very similar statistically (as in the case of Federer and Djokovic), their
 particular opponent is a key factor in determining the outcome of the tennis
 match.
\end_layout

\begin_layout Subsubsection*
Using Service & Return Points Won
\end_layout

\begin_layout Standard
As mentioned earlier, to create the past opponent profiles for a player,
 we analyze the player's past 100 matches against all opponents.
 Each match corresponds to an individual record; hence, if a player has
 played against a specific opponent multiple times, each encounter is represente
d as a separate record.
 For each of the past 100 matches, out of all match statistics, only the
 service points won and return points won percentages of each opponent are
 used for the next phase, which is the clustering phase.
 There are a few reasons that this decision was made.
 We have discussed in the background [section reference] the importance
 of the service points and return points won percentages to the overall
 outcome of the tennis match.
 In fact, we later use only those numbers to predict the probability of
 a player winning a match [section reference to 3].
 
\end_layout

\begin_layout Standard
It is important, however, to keep in mind specific cases where a player
 has won more points overall in a match, but has still lost the game.
 For instance, in the 2009 Australian Open Final between Roger Federer and
 Rafael Nadal, Federer won 174/347 points (50.14% of points) while Nadal
 won 173/347 points (49.85% of points), although Federer lost the match.
 Additionally, 
\shape italic
both
\shape default
 Nadal and Federer won 59% of their service points and 40% of their return
 points.
 However, cases like these are rare in tennis, and we can thus consider
 the service and return points won statistics to be good approximations
 for a large majority of tennis matches.
\end_layout

\begin_layout Standard
Other match statistics available that have been scraped using our web scraper
 include the number of aces in a match, break points won, break points saved,
 etc.
 However, this information wasn't used because they are not a good descriptor
 of overall match performance.
 For example, a player that relies on his fast service might have a lot
 of aces in a match, but this has little bearing on how well he performed
 overall in a match.
 In addition, statistics like aces and break points only count for a very
 small number of points relative to the entire match, and are poor indicators
 of an overall match.
 Service and return points 
\end_layout

\begin_layout Standard
A key advantage of looking at all of a specific player's matches is that
 the data is normalised between his different opponents.
 For example, one player's points won on serve percentage might be higher
 than that of another player's, but the reason might be because he has played
 weaker opponents.
 By later clustering based on a specific player's matches, we can ensure
 that the service and return points won percentages are normalised, as they
 are from matches against a specific opponent.
\end_layout

\begin_layout Standard
In our overall model, for a match up between player A and player B, we first
 look at all their previous encounters.
 We look at all the players that have performed similarly to B in terms
 of service points and return points won percentages.
 We get this group of players by using clustering techniques, such as k-means,
 which we describe in further detail later in section [Section reference
 to clustering techniques].
 This is the set of similar players that we use later in Section 2.2.1 [section
 reference to spw Si] to generate predictions.
\end_layout

\begin_layout Subsection
Clustering
\end_layout

\begin_layout Standard
In the last section, we looked at the various attributes that we use to
 describe players in both types of profiles.
 For example, in the past opponent profiles, we have used service and return
 points won percentages to characterise a player's performance.
 In addition, in the general player profiles, we have used a variety of
 different statistics including players' win rate on different courts and
 serve speed.
 In this section, we focus on how we use clustering to classify these player
 statistics and attributes into different clusters.
 
\end_layout

\begin_layout Subsubsection
Clustering the general player profiles 
\end_layout

\begin_layout Standard
To group the general player profiles, discussed in section [section reference],
 into clusters, we use the software, RapidMiner.
 As described in the Background [section reference], RapidMiner is a platform
 that provides a complete environment for machine learning and data mining.
 An image of how RapidMiner is used can be seen in Figure [figure reference].
 We design a process which:
\end_layout

\begin_layout Enumerate
Reads our CSV file: The CSV file that we read is just a list of players
 and their attributes, that we created in section [section reference]
\end_layout

\begin_layout Enumerate
Select attributes & Set roles for clustering: We select all the fields that
 need to be used in the clustering and their respective roles.
 For example, the role of the 'player name' field is a 'label', not an attribute
, since we do not want to cluster by the player names.
 We set the roles of all other fields to the 'attribute' target role, since
 we want it to be used in the overall clustering.
\end_layout

\begin_layout Enumerate
Clustering: We focus on the k-means algorithm, and we vary its parameters
 for different trials.
 The output of each of these algorithms are compared in Section [section
 reference]
\end_layout

\begin_layout Enumerate
Write CSV: This ends the process by appending a column to the input CSV
 file which contains the cluster that each player belongs to.
 This is the output file that is read by my Python program to find similar
 players.
\end_layout

\begin_layout Subsubsection*
Implementation in overall system
\end_layout

\begin_layout Standard
Python code has been developed to read the output CSV from RapidMiner and
 find players belonging to a particular cluster.
 An excerpt of RapidMiner's CSV output can be seen in Figure [figure reference].
 Python code is reproduced in Figure [figure reference]
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

def get_similar_profile_players(player2):
\end_layout

\begin_layout Plain Layout

	f = open("profiles_clustered.csv")
\end_layout

\begin_layout Plain Layout

	clustered_profiles = csv.DictReader(f)
\end_layout

\begin_layout Plain Layout

	for player in clustered_profiles: 		
\end_layout

\begin_layout Plain Layout

		if(player["player"]==player2:			
\end_layout

\begin_layout Plain Layout

			cluster = player["cluster"]
\end_layout

\begin_layout Plain Layout

		break
\end_layout

\begin_layout Plain Layout

	f.seek(0)
\end_layout

\begin_layout Plain Layout

	similar_players = [] 	
\end_layout

\begin_layout Plain Layout

	for player in profiles_clustered: 		
\end_layout

\begin_layout Plain Layout

		if player["cluster"]==cluster:
\end_layout

\begin_layout Plain Layout

			similar_players.append(player["player"]) 	
\end_layout

\begin_layout Plain Layout

	return similar_players
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Figure [figure reference], we find similar players to 'player2', which
 is a string of the player's name.
 We first iterate through the RapidMiner's CSV output by opening the file
 and loading it into a Python dictionary list.
 We then find the cluster that the player belongs to by iterating through
 the file, and setting the 'cluster' variable when we find the required
 player's cluster.
 Once we find the required cluster, we iterate through the file once more
 to find players which share the same cluster, returning this list of players
 at the end of the function.
 It is useful to note that 'player2' itself is included in the list of similar
 players returned by the function, because we consider 'player2' to be similar
 to itself.
 The output list that is returned is used in Section 2.3.1 [section reference]
 to create predictions of tennis matches.
\end_layout

\begin_layout Subsubsection*
Clustering algorithms
\end_layout

\begin_layout Subsubsection*
k-means
\end_layout

\begin_layout Standard
The k-means algorithm was explained in the Background section [section reference
].
 The algorithm aims to partition a set of n observations into a k number
 of clusters.
 There are two important aspects that need to be considered when using this
 algorithm:
\end_layout

\begin_layout Enumerate

\series bold
Initialization
\series default
: The k-means algorithm is very sensitive to the order of the dataset.
 This is because the first step involves randomly selecting cluster centres
 or centroids.
 RapidMiner has a feature called 'Determine good start values' which we
 have made use of in the clustering.
 This feature determines the first k centroids using the K-Means++ heuristic
 described in Artur's and Vassillvitskii's 
\begin_inset Quotes eld
\end_inset

k-means++: The Advantages of Careful Seeding
\begin_inset Quotes erd
\end_inset

 [reference].
 This ensures that the results of the clustering is the same over repeated
 trials.
\end_layout

\begin_layout Enumerate

\series bold
Value of k:
\series default
 The k-means algorithm is considered to be an extremely simple and efficient
 algorithm.
 However, it involves knowing the value of k prior to the clustering.
 This value of k determines how many clusters there will be in the result.
 One straightforward rule of thumb sets the value of k to 
\begin_inset Formula $\approx\sqrt{n/2}$
\end_inset

 where n is the number of observations in the dataset.
 There are other more advanced methods such as analyzing the gap statistic,
 or using an information criterion approach.
 When choosing a value for k, it is important to keep in mind that in this
 project, this value of k is equal to the number of different playing styles.
 For example, we are analyzing a total of over 30 players and if we want
 to have approximately 6 players in each cluster (or playing style), we
 can select the value of k to be 5.
 The appropriate value of k varies based on the application.
 We tested a variety of different values of k to find which gave and present
 the plots next.
 We also try to find the optimal number of centroids (value of k) using
 X-Means, a clustering algorithm which extends the k-means approach and
 uses the Bayesian Information Criteria (BIC) to find the appropriate number
 of centroids.
\end_layout

\begin_layout Standard
DIAGRAMS TRYING MANY DIFFERENT K's, showing centroids clearly.
 think about doing graphs in excel if cant get the labels properly
\end_layout

\begin_layout Standard
one of the diagrams is x-means
\end_layout

\begin_layout Subsubsection*
k-medoids
\end_layout

\begin_layout Standard
As described in the background, the k-medoids algorithm is very similar
 to the k-means algorithm.
 The only difference is that k-medoids chooses actual datapoints as centres,
 instead of imaginary centroids as in k-means.
 In k-medoids we try classify a player according to a real data point i.e.
 a real player.
 Thus, we cluster players that match an exact existing type of player (centroid)
, unlike in k-means where we cluster the players that match an imaginary
 centroid.
 For completeness, we plot the clusters of k-medoids to investigate any
 further trends in Figures [figure reference in the appendix??].
 
\end_layout

\begin_layout Standard
--changing aroudn the distance measure
\end_layout

\begin_layout Subsubsection
Past opponent profile clustering
\end_layout

\begin_layout Standard
To recall, we create a separate past opponent profile for each player in
 our dataset.
 This profile consists of a player's past 100 matches, along with their
 opponent's serve and return points won percentages in each of these matches.
 Unlike the general profile clustering, we implement the clustering algorithm
 (k-means) in Python instead of RapidMiner to perform the clustering.
 The reason for this is that the general profile clustering only needs to
 be clustered once at the start, since the attributes of each player don't
 change from match to match.
 However, in this section, as we make a prediction for a match in a list
 of fixtures, we add that game to the a player's dataset.
 This has the significant advantage of clusters being constantly updated,
 since we iterative cluster the dataset adding new data from every game.
\end_layout

\begin_layout Standard
For the k-means clustering algorithm, we use the clustering library PyCluster
 and scientific toolkit SciPy.
 PyCluster provides its own implementation of the k-means algorithm and
 it is used in the following way:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

def kmeans_cluster(past_opponent_records):
\end_layout

\begin_layout Plain Layout

	# create a new list serve_return with only serve 
\end_layout

\begin_layout Plain Layout

	# points (rec[0]) and return points won 
\end_layout

\begin_layout Plain Layout

	# (rec[1]) percentages
\end_layout

\begin_layout Plain Layout

	for rec in past_opponent_records:
\end_layout

\begin_layout Plain Layout

		serve_return.append([float(rec[0]),float(rec[1])])
\end_layout

\begin_layout Plain Layout

	# chooses appropriate k-value for k-means
\end_layout

\begin_layout Plain Layout

	k = get_k_value(serve_return)
\end_layout

\begin_layout Plain Layout

	labels,error,nfound=Pycluster.kcluster(scipy.array(serve_return), k)
\end_layout

\begin_layout Plain Layout

	return labels
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As we can see, this function takes the argument 'past_opponent_records',
 which is a list of records.
 Each record contains the opponent's name, odds for a player to win the
 match, the serve and return points won percentages, as well as additional
 match statistics.
 Since we only want to cluster according to the serve and return points
 won percentages, we create a new list which contains only the serve and
 return points won percentages.
 We then pass this list to Pycluster's kcluster function, which is the k-means
 algorithm, along with the specified value of k.
 Pycluster's kcluster function only accepts arrays, not lists, so we use
 the Scipy library to convert from a list to an array.
\end_layout

\begin_layout Standard
One of the function's return values is 'labels', a list of integers where
 each integer corresponds to a separate cluster.
 A straightforward example of the output of the Pycluster function is shown
 in Figure [figure reference].
 In Figure [figure reference], we input four service and return points won
 percentages, and provide a k-value of 2 i.e.
 2 clusters.
 The output is in the final line 
\begin_inset Quotes eld
\end_inset

clusters: [0 1 0 1]
\begin_inset Quotes erd
\end_inset

, and this simply means that the first and third set of values belong to
 cluster 0, while the remaining values belong to cluster 1.
\end_layout

\begin_layout Subsubsection*
Data Preprocessing
\end_layout

\begin_layout Standard
--injury flags and outliers removal
\end_layout

\begin_layout Subsubsection*
Limitations
\end_layout

\begin_layout Standard
rely on them playing multiple times for accurate set of similar players.
 if they played only once then too biased on that result esp if it was a
 shock defeat results are very skewed.
 fortunately we have focused analysis on top 30 and they play each other
 fairly often
\end_layout

\begin_layout Standard
too biased on their last encounters and shock defeats- initially only looked
 at previous encounter, but decided to look at all their encounters to minimize
 this limitation
\end_layout

\begin_layout Standard
COPIED FROM 2.1 In our overall model, for a match up between player A and
 player B, we first look at all their previous encounters.
 We look at all the players that have performed similarly to B in terms
 of service points and return points won percentages.
 We get this group of players by using clustering techniques, such as k-means,
 which we describe in further detail later in section [Section reference
 to clustering techniques].
 This is the set of similar players that we use later in Section 2.2.1 [section
 reference to spw Si] to generate predictions.
\end_layout

\begin_layout Subsubsection*
Up till this point : how we generate a set of similar players, dataflow
 picture
\end_layout

\begin_layout Subsection
Difference in service points won
\end_layout

\begin_layout Standard
As mentioned earlier in the report, a key indicator of a player's performance
 in a tennis match depends on the percentage of points won on serve by each
 player.
 These point-winning probabilities have been used in most tennis models
 till date and are the key inputs to hierarchical Markov tennis models,
 which rely on these point winning probabilities to return a probability
 of a player winning a match.
 
\end_layout

\begin_layout Standard
O'Malley [reference] reasoned that it is the difference between the serve
 winning probabilities of each player that is integral to calculating a
 player's point winning probability and hence overall match winning probability.
 It is important to note that the actual values of the point winning probabiliti
es themselves are not as crucial as the relative difference between them.
\end_layout

\begin_layout Standard
The above findings have been used in recent tennis models, such as in the
 common opponent model proposed by Knottenbelt [reference], as well as in
 this project.
 In the common opponent model, the difference in service points won by each
 player is derived from each player's relative performance against common
 opponents.
 For example, to model how two players, player 
\shape italic
A
\shape default
 and player 
\shape italic
B
\shape default
, would play against each other, we look at the difference in service points
 won by 
\shape italic
A
\shape default
 and 
\shape italic
B
\shape default
 against a set of common opponents, 
\shape italic

\begin_inset Formula $C_{i}$
\end_inset


\shape default
's.
 We can then add the differences, which are either positive or negative,
 to the probability of winning a point on serve for each player in a match
 up between 
\shape italic
A
\shape default
 and 
\shape italic
B
\shape default
.
 The common opponent model takes advantage of the element of transitivity
 in tennis across particular i.e.
 if player A is better than a player C, and player C is better than player
 B, then player A is likely to be better than player B.
 However, this is not necessarily true, since players might have completely
 different styles and may perform better against certain types of players.
 This is a limitation that our proposed model addresses through the use
 of similar players.
 NOTE: COMMON OPP MODEL IS TRANSITIVITY OVER PARTICULAR PLAYERS, WHILE MY
 MODEL IS OVER SETS OF PLAYERS SO MORE ACCURATE
\end_layout

\begin_layout Subsubsection
Formulas and Implementation
\end_layout

\begin_layout Standard
We incorporate the ideas of similar players discussed previously into the
 difference in service points won method.
 Instead of common opponents like in the common opponent model, we use similar
 opponents through player profiles.
 
\end_layout

\begin_layout Standard
In a match between player A and B as before, we instead look first at the
 difference in the percentage of service points won between A and a set
 of 'similar' opponents to B.
 We then look at the difference in the percentage service points won between
 B and a set of 'similar' opponents to A.
 These differences correspond to the advantage player A has over player
 B and the advantage player B has over player A, respectively.
 Either of these advantages can be negative, which will represent a disadvantage
 for a player over another.
 
\end_layout

\begin_layout Standard
The below formulas describe how each is calculated.
 These formulas are very similar to what has been presented by Knottenbelt
 [reference], except that instead of common opponents
\begin_inset Formula $C_{i}$
\end_inset

, we use similar opponents
\begin_inset Formula $S_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
For each similar opponent, 
\begin_inset Formula $S_{i}$
\end_inset

, we calculate 
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

, which is the measure of the advantage Player A has over Player B in terms
 of the percentage of service points won.
 Note that spw(X,Y) is the percentage of points won on serve by Player X
 against Player Y, while rpw(X,Y) is the percentage of points won on return
 by Player X against Y:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\triangle_{i}^{AB}=(spw(A,S_{i})-(1-rpw(A,S_{i})))-(spw(B,S_{i})-(1-rpw(B,S_{i})))
\]

\end_inset


\end_layout

\begin_layout Standard
To model a game between player A and B, we can influence the probability
 of winning a point on serve by adding the value of
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

to player A's probability of winning a point on serve, and subtracting the
 value of
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

from player B's probability of winning a point on serve.
 This is done in the following way:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(A\, beats\, B)\approx\frac{M_{3}(0.6+\triangle_{i}^{AB},\,(1-0.6))+M_{3}(0.6,\,1-(0.6-\triangle_{i}^{AB}))}{2}
\]

\end_inset


\end_layout

\begin_layout Standard
The function 
\begin_inset Formula $M_{3}(p,q)$
\end_inset

 was proposed by O'Malley [reference], and was introduced earlier in the
 background section [section reference].
 It takes as inputs p, which is the probability of player A winning a point
 on his serve, and q, which is the probability of player B winning a point
 on his serve, and outputs a probability of player A beating B in a three
 set match using a hierarchical model.
 For a five set match, we use
\begin_inset Formula $M_{5}(p,q)$
\end_inset

 instead of 
\begin_inset Formula $M_{3}(p,q)$
\end_inset

.
 We revisit O'Malley's formulae in section 3.2 [Reference].
 In equation [equation reference], we take the average of the two match
 winning probabilities calculated.
 
\end_layout

\begin_layout Standard
---------------
\end_layout

\begin_layout Standard
implementation - talk about how the above was written in python
\end_layout

\begin_layout Standard
dealing with multiple clusters ->taking recently played of other cluster
 etc, use other cluster information
\end_layout

\begin_layout Standard
This specific set of similar opponents is found through clustering techniques
 over different sets of data which we discussed above
\end_layout

\begin_layout Section
Estimating a player's match winning probability
\end_layout

\begin_layout Standard
The calculation of a player's match winning probability is a key aspect
 of this project.
 In the previous section, we discussed how to calculate 
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

, which is the value that represents the advantage or disadvantage that
 a player A has over player B in terms of the proportion of service points
 won against opponent Si.
 We use this value to influence the probability of winning a point on serve
 for each player in a match between player A and player B.
 Using this player's probability of winning a point on serve, we calculate
 the overall probability of a player winning a match.
\end_layout

\begin_layout Standard
O'Malley [reference] and Barnett [reference] have proposed hierarchical
 models of computing the game, set, and match winning probabilities using
 only the probabilities of a player winning a point on serve and on return.
 Both of these methods have been briefly discussed in the background section
 of the report.
 There are key differences between these two models.
 Barnett's model is implemented through a hierarchical Markov model, using
 recursive formulae to derive the probabilities of winning a game, set,
 and hence, match from any state (these states refer to particular game
 scores).
 On the other hand, O'Malley's model consists of equations which take the
 binary event of a player winning a point as a Bernoulli random variable.
 For this project, we have implemented O'Malley's model to calculate the
 match winning probability because we wanted to avoid the computational
 overhead of recursive methods, which are significant in this project, where
 we later predict a set of several hundred tennis matches.
 It is important to note, however, that the approach used in this project
 can be also used easily Barnett's model, as well as any other hierarchical
 model which takes as input the probabilities of a player winning a point
 on serve and return.
\end_layout

\begin_layout Subsection
Assumptions
\end_layout

\begin_layout Standard
A key assumption that both of these aforementioned models (Barnett's and
 O'Malley's) take into account is that each point is independently and identical
ly distributed (iid).
 This assumption was briefly touched upon in the background section of this
 project report [reference to section chapter].
 This iid assumption is that the probability of a player winning a point
 is independent of the outcome of the previous point(s) and it remains constant
 throughout the entire match.
 This is why both of the above models can be modeled as hierarchical models
 that take only the service points and return points won percentages of
 a player as inputs.
 It is intuitively difficult to accept that this assumption, especially
 considering several common phenomena that exist in sport such as fatigue
 and psychological momentum.
 For example, it is not unlikely that a player wins less points on his serve
 as the match progress due to fatigue and exhaustion.
 In addition, a player's momentum is considered by many to play a crucial
 role in the outcome of individual points.
\end_layout

\begin_layout Standard
This assumption was analyzed by Klaasen and Magnus [1].
 They tested the iid assumption using point to point data on four years
 of Wimbledon men's and women's singles matches.
 They reasoned that points are neither 
\shape italic
exactly
\shape default
 independently nor identically distributed.
 In other words, a player winning the previous point had a positive impact
 on a player winning the next point.
 However, most importantly, they found that deviations from the iid assumption
 were small and hence, this iid assumption can still be considered to be
 a good approximation.
 There are further useful observations that were presented in the same paper
 by Klaasen and Magnus: firstly, they observed that deviations change based
 on the 'importance' of points.
 Secondly, they found that the weaker the player, the stronger are the effects
 of these deviations.
 This is an additional reason for why we have focused our study on the top
 ranked players, to aim to minimise deviations from the iid assumption.
\end_layout

\begin_layout Subsection
Implementation
\end_layout

\begin_layout Standard
We have implemented O'Malley's key formulas for each stage of the hierarchical
 model in Python.
 Using point level statistics (probability of each player winning a point
 on his serve), we can calculate the probability of a player winning a game
 and a tiebreaker game.
 We then use these calculated probabilities to derive the probability of
 a player winning a set and also hence winning the match.
 As an example, the formulas for the game level and three or five set match
 level of the hierarchy are revisited below.
 All formulas have been presented in the Background [reference].
\end_layout

\begin_layout Subsubsection*
Game Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(p)=P(player\, wins\, game)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{i=0}^{\infty}P(player\, wins\, game\, losing\, i\, points)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}+4p^{4}(1-p)+10p^{4}(1-p)^{2}+20p^{3}(1-p)^{3}\centerdot\sum_{i=3}^{\infty}\{2p(1-p)\}^{i-3}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}(15-4p-\frac{10p^{2}}{1-2p(1-p)})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset

 refers to the probability of a player winning a point on serve
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

The formula in Equation [equation reference] covers each case for a player
 to win a game on his serve.
 He can either win four straight service points, win four points to win
 a game while losing one or two points during the game, and finally the
 case for 30-30/Deuce.
 In the Deuce case, the number of points played until the server wins follows
 a geometric distribution since the game can in theory go on for an infinity
 amount of points.
\end_layout

\begin_layout Subsubsection*
Set Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S(p,q)=\sum_{i=1}^{21}B(i,1)G(p)^{B(i,2)}(1-G(p))^{B(i,3)}G(q)^{B(i,4)}(1-G(q))^{B(i,,5)}
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\qquad\:\times(G(p)G(q)+(G(p)(1-G(q))+(1-G(p))G(q))T(p,q))^{B(i,6)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p,q$
\end_inset

 refers to the probability of each player winning a point on serve
\end_layout

\begin_layout Standard
\begin_inset Formula $T(p,q)$
\end_inset

 refers to the probability of a player winning a tiebreaker game
\end_layout

\begin_layout Standard
\begin_inset Formula $B(x,y)$
\end_inset

 refers to the coefficient matrix calculated by O'Malley.
\end_layout

\begin_layout Standard
The formula in Equation [equation reference] sums up the probabilities of
 all 21 game scores combinations in a set.
 
\begin_inset Formula $S(p,q)$
\end_inset

 is derived from the probabilities of each player winning a game (
\begin_inset Formula $G(p)$
\end_inset

 and
\begin_inset Formula $G(q)$
\end_inset

 ) and the probability of winning a tiebreaker, 
\begin_inset Formula $T(p,q)$
\end_inset

.
 The probability formula for the tiebreaker game has been described in the
 Background [section reference].
 To implement the definition of the matrix B(x,y), the Python library 'Numpy'
 was used, which provided increased readability versus an implementation
 using a list of lists.
 This matrix is presented in the appendix [reference].
\end_layout

\begin_layout Subsubsection*
Match Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{3}(p,q)=S(p,q)^{2}[1+2(1-S(p,q))]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{5}(p,q)=S(p,q)^{3}[1+3(1-S(p,q))+6(1-S(p,q))^{2}]
\]

\end_inset


\end_layout

\begin_layout Standard
The formula in Equation [equation reference] are for best of 3 matches and
 best of 5 matches respectively.
 For Grand Slam matches, the second formula was used, since all Grand Slam
 matches are best of five set encounters.
 For other matches on the ATP tour, the best of three set formula was used.
\end_layout

\end_body
\end_document
