#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding T1
\font_roman lmodern
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 4cm
\topmargin 4.5cm
\rightmargin 4cm
\bottommargin 4.5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Background
\end_layout

\begin_layout Subsection
Scoring System in a Tennis Match
\end_layout

\begin_layout Standard
Tennis matches can be either singles or doubles contests, with singles matches
 played between two players while doubles matches played between four.
 We focus on singles matches in this project.
\end_layout

\begin_layout Standard
To win a tennis match, a player must win a certain amount of sets, which
 is determined before the game.
 Grand Slam men tournaments involve matches that are best of five sets,
 which means a player must win three sets to win the match.
 Most tournaments, including all ATP tournaments (tournaments that count
 towards a player's ranking), involve matches that are a best of three sets,
 where a player needs to win two sets to win the match.
 A set is made up of multiple games, and hence, for a player to win a set,
 he must win six games, except in special cases.
 These special cases are the following: 1) When both players have won five
 games, a player must now win a total of seven games (additional two consecutive
 games) to win the set, and 2) When both players have won six games, a tiebreak
 is played in most situations to decide the outcome of the set.
 Whether or not players play a tiebreak game depends on the rules of the
 tournament.
\end_layout

\begin_layout Standard
A game consists of a series of points.
 A player starts a point by serving to his opponent, and a complete game
 is played with the same player serving.
 The player serving alternates after every game.
 To win a game, a player must win at least four points in total, and at
 least two points more than his opponent.
 Points are counted in the following way: zero, one, two, and three points
 are referred to as love, fifteen (15), thirty (30), and fourty (40), respective
ly.
 We have the exception where each player scores three points each, which
 is called a 
\begin_inset Quotes eld
\end_inset

deuce
\begin_inset Quotes erd
\end_inset

.
 In this situation, a player must win two additional points consecutively
 to win the game.
 The first point is called an 
\begin_inset Quotes eld
\end_inset

advantage
\begin_inset Quotes erd
\end_inset

 for the player in the lead.
 If the opponent scores when the player is in an 
\begin_inset Quotes eld
\end_inset

advantage
\begin_inset Quotes erd
\end_inset

 situation, the score gets reduced back to a 
\begin_inset Quotes eld
\end_inset

deuce
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
As mentioned earlier, players play a tiebreaker game in most cases where
 both players have six games each in the set.
 A player wins the tiebreak if has won at least seven points in the tiebreak
 and has two points or more than his opponent (e.g.
 valid scores include 7-2 and 10-8).
 Serving is unlike regular games in a tiebreaker, as serve alternates.
 The player who did not serve in the previous game serves the first point
 of the tiebreak, while his opponent serves the following two points.
 The serve alternates every two points in a tiebreak.
\end_layout

\begin_layout Subsection
Modelling in Tennis
\end_layout

\begin_layout Standard
Tennis matches are very suitable to statistical modelling.
 This is because it is an individual sport with two outcomes, meaning that
 there is no need to consider team dynamics.
 The scoring system can also be modelled in a straightforward way as there
 are only two outcomes for a match.
 Additionally, every game has a simple point based system, and players serve
 alternately for each game in very similar circumstances.
\end_layout

\begin_layout Standard
For the ease of modelling a tennis game, most papers take the assumption
 that points in a tennis match are identically and independently distributed
 (i.i.d.).
 This means that the probability of a player winning a point is independent
 of the outcome of the point played before and after and it remains constant
 throughout the entire match.
 This assumption was analyzed by Klaasen and Magnus[reference 1].
 They found that points were neither identically nor independently distributed.
 However, they concluded that the deviations from the i.i.d.
 assumption were small and hence, this assumption is considered to be a
 good approximation in many cases.
 This deviation is small due to the fact that tennis is a very repetitive
 game, with each player aiming to win a point under largely similar circumstance
s, except for in high pressure situations such as break points (when the
 non-serving player has a chance to win a game).
 Certainly, psychology and momentum do play a part in tennis matches, but
 as in any sport, its extremely difficult or rather impossible to predict
 a player's psychology at any time.
\end_layout

\begin_layout Standard
With this assumption of points being identically and independently distributed,
 various papers model tennis matches using a hierarchical Markov model,
 since its a hierarchical sport, with the different levels of heirarchy
 being at the point, game, set and match levels.
 Markov chains have the Markov property of being 'memoryless', meaning that
 the next state is only dependent on the current state.
 This fits with the i.i.d.
 assumption discussed previously.
\end_layout

\begin_layout Subsection
Stochastic Markov chain
\end_layout

\begin_layout Standard
A discrete time Markov chain is a mathematical system that undergoes transitions
 from one to another.
 It involves a collection of random variables which characterize a random
 process.
 A process has a Markov property if the conditional probability distribution
 of future states of the process depends on only the current state and is
 independent of the past.
 Discrete-time random processes, which are the processes Markov chains character
ise, involve systems which are in a specific state at a specific step.
 These steps are often considered as steps in time.
 
\end_layout

\begin_layout Standard
To define the term, a Markov chain is a sequence of random variables 
\begin_inset Formula $X_{1},$
\end_inset


\begin_inset Formula $X_{2},$
\end_inset


\begin_inset Formula $X_{3},...$
\end_inset

 with the Markov property.
 [reference 4] The Markov property can be formally expressed as 
\begin_inset Formula 
\[
P(X_{n+1}=x\,|\, X_{1}=x_{1},\, X_{2}=x_{2},...,\, X_{n}=x_{n})=P(X_{n+1}=x\,|\, X_{n}=x_{n})
\]

\end_inset

The different values of 
\begin_inset Formula $X_{j}$
\end_inset

 form the state space S of the chain.
 
\end_layout

\begin_layout Standard
A Markov model is a stochastic model that models the state of a system with
 (usually discrete) random variable that varies over time.
 It can be described as the depiction of a set of all Markov chains for
 a given event.
 Markov chains and models are usually represented as directed graphs.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:markov"

\end_inset

 shows an example of a Markov model used to describe a game in a tennis
 match, where the win state represents a win for the current server.
 In Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:markov"

\end_inset

, there are the merged states of 30-30/Deuce, 30-40/30-Advantage, and 40-30/40-A
dvantage.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
A directed graph of a Markov model for a tennis game
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:markov"

\end_inset


\end_layout

\begin_layout Plain Layout

\shape italic
p represents the probability of winning a point for the server
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Tennis Equations
\end_layout

\begin_layout Standard
James O'Malley[reference 2], in his paper 
\begin_inset Quotes eld
\end_inset

Probability Formulas and Statistical Analysis in Tennis
\begin_inset Quotes erd
\end_inset

, and Tristan Barnett[reference 3], in his paper 
\begin_inset Quotes eld
\end_inset

Combining player statistics to predict outcomes of tennis matches,
\begin_inset Quotes erd
\end_inset

 use hierarchical models to develop formulas to help us calculate the probabilit
ies of players winning a tennis match.
 As we will see in this section, the serve and return points won statistics
 are key values used to calculate a probability of a player winning a game,
 set and hence match, especially in a hierarchical sport like tennis, where
 each point is played under roughly the same conditions.
\end_layout

\begin_layout Subsubsection
O'Malley's Formulae
\end_layout

\begin_layout Standard
Using point level statistics (probability of each player winning a point
 on his serve), we can calculate the probability of a player winning a game
 and a tiebreaker game.
 We then use these calculated probabilities to derive the probability of
 a player winning a set and also hence winning the match.
\end_layout

\begin_layout Standard
Using the idea that the probability that a player wins a point is a Bernoulli
 random variable 
\begin_inset Formula $p$
\end_inset

, O'Malley [reference 2] derived the following expressions:
\end_layout

\begin_layout Subsubsection*
Probability of a player winning a game
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(p)=P(player\, wins\, game)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{i=0}^{\infty}P(player\, wins\, game\, losing\, i\, points)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}+4p^{4}(1-p)+10p^{4}(1-p)^{2}+20p^{3}(1-p)^{3}\centerdot\sum_{i=3}^{\infty}\{2p(1-p)\}^{i-3}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}(15-4p-\frac{10p^{2}}{1-2p(1-p)})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset

 refers to the probability of a player winning a point on serve
\end_layout

\begin_layout Standard
O'Malley, in this equation, considers four different scenarios from which
 the game can be won: the player can win without losing any points, losing
 one point, losting two points, and winning the game after the score is
 
\begin_inset Quotes eld
\end_inset

deuce
\begin_inset Quotes erd
\end_inset

, where three or more points are lost.
 The last situation follows a geometric sequence since the game can in theory
 go on for an infinite amount of points (alternates between Deuce and Advantage).
 The final formula 
\begin_inset Formula $G(p)$
\end_inset

 is given by the sum of the joint probabilities of winning the game losing
 a certain number of points.
 O'Malley uses the above formula to describe formulae for winning a set
 and consequently a match.
 These tennis equations have helped greatly as they allow us to straightforwardl
y and easily develop quick programs to calculate the probability of a player
 winning a tennis match with accuracy, without the need of using recursive
 hierarchical models which have a significant computational overhead.
\end_layout

\begin_layout Subsubsection*
Probability of a player winning a tiebreaker
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
TB(p,q)=\sum_{i=1}^{28}A(i,1)p^{A(i,2)}(1-p)^{A(i,3)}q^{A(i,4)}(1-q)^{A(i,5)}d(p,q)^{A(i,6)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
where\: d(p,q)=pq[1-\{p(1-q)+(1-p)q\}]^{-1}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
and\: A(i,j)\: is\: the\: ijth\: element\: of\: the\:28\times6\: matrix\: A
\]

\end_inset


\end_layout

\begin_layout Standard
Coefficient matrix 
\begin_inset Formula $A(x,y)$
\end_inset

 is presented in the Appendix [appendix reference].
\end_layout

\begin_layout Standard
\begin_inset Formula $p,q$
\end_inset

 refers to the probability of each player winning a point on serve
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
The key difference between a regular game and a tiebreaker is the fact that
 the service alternates between the two players after every odd number of
 points played.
 Additionally, since both players serve, we introduce a variable 
\begin_inset Formula $q$
\end_inset

, which refers to the probability of the second player winning a point on
 serve, in addition to the previously used variable 
\begin_inset Formula $p$
\end_inset

, used in the formula for the probability of a player winning a game on
 his service.
 There is a significantly more number of terms in the tiebreaker formula
 than there is in the formula for a player to win a game because there are
 a higher number of distinct scores possible in a tiebreaker.
\end_layout

\begin_layout Subsubsection*
Probability of a player winning a set
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S(p,q)=\sum_{i=1}^{21}B(i,1)G(p)^{B(i,2)}(1-G(p))^{B(i,3)}G(q)^{B(i,4)}(1-G(q))^{B(i,,5)}
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\qquad\:\times(G(p)G(q)+(G(p)(1-G(q))+(1-G(p))G(q))T(p,q))^{B(i,6)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
where\: B(i,j)\: is\: the\: ijth\: element\: of\: the\:21\times6\: matrix\: B
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p,q$
\end_inset

 refers to the probability of each player winning a point on serve
\end_layout

\begin_layout Standard
Coefficient matrix 
\begin_inset Formula $B(x,y)$
\end_inset

 is presented in the Appendix [appendix reference]
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
It can be seen that 
\begin_inset Formula $S(p,q)$
\end_inset

 is derived from the probabilities of each player winning a game (
\begin_inset Formula $G(p)$
\end_inset

 and
\begin_inset Formula $G(q)$
\end_inset

 ) and the probability of winning a tiebreaker, 
\begin_inset Formula $T(p,q)$
\end_inset

.
 When the scores reach 6-6, a tiebreaker is played.
 Hence, this equation is different from the others because the equation
 does not involve a geometric sequence of the game winning probabilities.
\end_layout

\begin_layout Subsubsection*
Probability of a player winning a match
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{3}(p,q)=S(p,q)^{2}[1+2(1-S(p,q))]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{5}(p,q)=S(p,q)^{3}[1+3(1-S(p,q))+6(1-S(p,q))^{2}]
\]

\end_inset


\end_layout

\begin_layout Standard
The formulae in Equation [equation reference] are for best of 3 matches
 and best of 5 matches respectively.
 For Grand Slam matches, the second formula is used, since all Grand Slam
 matches are best of five set encounters.
 For other matches on the ATP tour, the best of three set formula was used.
\end_layout

\begin_layout Standard
The equations are derived in a straightforward way.
 For the best of 3 matches, the probability of a player winning a match
 is the addition of the probability of the player winning a match in straight
 consecutive sets, and the probability of a player winning two sets and
 losing one.
 The formula for best of 5 matches is derived in the same way.
\end_layout

\begin_layout Subsubsection
Combining player statistics using Barnett and Clarke's formulae
\end_layout

\begin_layout Standard
There is a significant amount of data available regarding match statistics,
 but its important to combine them to produce an accurate estimation of
 the probability of winning a point.
 Barnett and Clarke[ reference 3] came up with the following formulae to
 combine certain statistics to give an accurate point winning probability
 on serve:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f_{i}=a_{i}b_{i}+(1-a_{i})c_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $f_{i}=$
\end_inset

percentage of points won on serve for player i.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $a_{i}$
\end_inset

= first serve percentage accuracy of player i
\end_layout

\begin_layout Standard
\begin_inset Formula $b_{i}$
\end_inset

= first serve win percentage of player i
\end_layout

\begin_layout Standard
\begin_inset Formula $c_{i}$
\end_inset

= second serve win percentage of player i
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
The above formula is straightforward to understand.
 The percentage of points won on serve for player i is the sum of the points
 won on the first serve and the points won on the second serve (when the
 player misses his first serve).
\end_layout

\begin_layout Standard
Taking into account the opponent, we have the following:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
g_{i}=a_{avg}d_{i}+(1-a_{avg})e_{i}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $g_{i}=$
\end_inset

percentage of points won on return for player i.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $a_{avg}$
\end_inset

= average first serve percentage across a range of players
\end_layout

\begin_layout Standard
\begin_inset Formula $d_{i}$
\end_inset

= percentage of points won on return of first service for player i
\end_layout

\begin_layout Standard
\begin_inset Formula $e_{i}$
\end_inset

= percentage of points won on return of second service for player i
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
We have a similar formula for the opponent, i.e.
 the player who is returning the service.
 The percentage of points the opponent wins returning the service is the
 sum of again the points won returning the first serve and those won returning
 the second service.
 In Barnett's paper,
\begin_inset Formula $a_{avg}$
\end_inset

refers to the average first serve percentage across the top 200 ATP players.
\end_layout

\begin_layout Standard
Finally, we want to combine both of these player statistics when a player
 i plays against a player j.
 In this case, the percentage of points won on serve for player i, 
\begin_inset Formula $f_{ij}$
\end_inset

, is below in equation [equation reference].
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f_{ij}=f_{t}+(f_{i}-f_{avg})-(g_{i}-g_{avg})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $f_{t}=$
\end_inset

average percentage of points won on serve for the specific tournament the
 match is in
\end_layout

\begin_layout Standard
\begin_inset Formula $f_{avg}=$
\end_inset

average percentage of points won on serve across a range of players
\end_layout

\begin_layout Standard
\begin_inset Formula $g_{avg}=$
\end_inset

average percentage of points won on return across a range of players
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
In the same paper, Barnett describes a hierarchical Markov model which,
 like O'Malley's tennis formulae, takes as input the serve winning probabilities
 of both players to come up with a probability of each player winning the
 match.
 It is important to note that the actual values of the point winning probabiliti
es themselves are not as crucial as the relative difference between them.
 O'Malley [reference] has also reasoned that it is the difference between
 the serve winning probabilities of each player that is integral to calculating
 a player's point winning probability and hence overall match winning probabilit
y.
 
\end_layout

\begin_layout Subsection
Clustering
\end_layout

\begin_layout Standard
Most models till date have used the above discussed ideas of Markov models.
 However, in this project we aim to take this one step further and encourage
 the use of machine learning in our analysis.
 Machine learning involves the development of systems that can learn from
 data.
 In this project, we will be data mining through large amounts of statistical
 data on professional tennis players, analyzing their key attributes, and
 finally grouping these players into different categories.
 A large part of the data mining process are the concepts of clustering
 and cluster analysis.
\end_layout

\begin_layout Standard
Cluster analysis is achieved by different algorithms that differ significantly
 in their notion of what defines a cluster.
 These algorithms' main aims are to take a data set and sort it into groups,
 allowing us to compare tennis players that are similar to one another,
 which is imperative for this project.
 There are a wide range of clustering algorithms that have been developed
 for data mining purposes.
 It was hence important to research into different algorithms, analyze the
 clusters formed by those algorithms and parameters, and choose a clustering
 algorithm aligned to the requirements of the problem.
 In this project, we focus on the k-means clustering algorithm and variations
 of it.
 
\end_layout

\begin_layout Subsubsection
K-means Clustering
\end_layout

\begin_layout Standard
The k-means clustering algorithm is a straightforward unsupervised learning
 algorithm that uses an iterative refinement technique.
 It classifies a data set through a certain number (referred to as the variable
 k) of specified clusters.
 The algorithm starts with these k random clusters and then examines each
 data point and assigns it to one of the centroids (i.e.
 the geometric center of the cluster) depending on the minimum variance/distance.
 There are various distance measures that can be used.
 For this project, we have chosen to use the standard Euclidean distance
 throughout.
 The centroid's position is recomputed everytime a data point is added to
 the cluster, by simply finding the mean of all the data points assigned
 to that cluster.
 After the centroid's position is recomputed, a new binding is needed to
 be done between the same datapoints and the new closer centroid.
 The algorithm continues iteratively until all the data set points are grouped
 into the final required number of clusters, and the centroids position
 don't change after any further iterations.
 
\end_layout

\begin_layout Standard
More formally, we have the cluster assignment step as the following [reference
 5]:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S_{i}^{(t)}=\{x_{p}:\parallel x_{p}-m_{i}^{(t)}\parallel^{2}\leq\parallel x_{p}-m_{i}^{(t)}\parallel^{2}\forall j,\,1\leq j\leq k\}
\]

\end_inset


\end_layout

\begin_layout Standard
where each data point 
\begin_inset Formula $x_{p}$
\end_inset

is assigned to exactly one 
\begin_inset Formula $S^{(t)}$
\end_inset

, and there is a set of 
\begin_inset Formula $m_{i}...m_{k},$
\end_inset

where k is the number f specified clusters.
 m's are the centroids.
\end_layout

\begin_layout Standard
This formula essentially states that a data point x is assigned to a cluster
 S if the variance/squared error term between the data point and centroid
 is minimized.
\end_layout

\begin_layout Subsubsection
K-medoids Clustering
\end_layout

\begin_layout Standard
K-medoids clustering is a variation of the k-means algorithm.
 The only difference is that k-medoids chooses actual datapoints as centres,
 instead of imaginary centroids as in k-means.
 The k-medoids clustering has been implemented by the Partitioning Around
 Medoids (PAM) algorithm, which works in the following way [reference http://anu
radhasrinivas.files.wordpress.com/2013/04/lesson8-clustering.pdf]:
\end_layout

\begin_layout Enumerate
In the initialization step, randomly select k data points out of all n observati
ons to be medoids.
 A medoid is essentially a data point which is 'least dissimilar' from all
 other data points.
\end_layout

\begin_layout Enumerate
According to a distance metric, say the Euclidean distance, we allocate
 each data point to the closest (most similar) medoid
\end_layout

\begin_layout Enumerate
For each medoid m and each non-medoid observation o, swap m and o and calculate
 the total cost (also known as the absolute error criterion) for the set
 of medoids.
 The cost between any two points 
\begin_inset Formula $(x,c)$
\end_inset

 is given by 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\sum_{i=1}^{d}|x_{i}-c_{i}|$
\end_inset

, where d is the dimension of the object.
 The total cost is the summation of the cost of all data objects from its
 medoid in its cluster.
\end_layout

\begin_layout Enumerate
Choose the set of medoids with the lowest total cost
\end_layout

\begin_layout Enumerate
Repeat steps 2-4 until medoids remain unchanged
\end_layout

\begin_layout Subsubsection
X-means Clustering
\end_layout

\begin_layout Standard
As described earlier, the k-means algorithm starts with a certain number
 of specified clusters, and assigns each data point to one of these clusters
 depending on the minimum variance.
 However, we do face the important decision on what the value of k should
 be set to, as this determines the number of clusters that we are left with.
 The first extreme involves setting the value of k to 1, which means that
 all data points form one cluster, which might give us a very irregular
 distribution.
 On the other end of the extreme, we have that all data points each form
 its own cluster.
 This means that the clusters are perfectly informative of the data, but
 that makes the clustering rather pointless, in addition to the fact that
 this will not allow us to predict new data.
 
\end_layout

\begin_layout Standard
This is where the X-means algorithm comes in.
 This algorithm was described in 
\begin_inset Quotes eld
\end_inset

X-means: Extending K-means with Efficient Estimation of the Number of Clusters
\begin_inset Quotes erd
\end_inset

 by Pelleg and Moore [reference to this paper].
 The algorithm takes as input a minimum k value and a maximum k value, and
 aims to find the optimal amount of clusters by optimizing information criteria,
 using a criterion known as the Bayesian Information Criterion (BIC).
\end_layout

\begin_layout Subsection
Tools
\end_layout

\begin_layout Subsubsection
RapidMiner
\end_layout

\begin_layout Standard
RapidMiner is a popular data mining tool that allows you to use several
 machine learning algorithms over a dataset through the same system.
 Several clustering algorithms, such as the k-means, k-medoids, and x-means
 algorithms, are included in the software itself, and we can tweak the algorithm
 settings where necessary.
 The software also provides us with other useful features such as the detection
 and removal of outliers.
 To use RapidMiner, users need to design processes, which consist of operators
 such as 'Clustering', 'Import Data', etc.
 Later in this report, we present the different processes that have been
 used in RapidMiner.
 A screenshot of the RapidMiner tool is shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:rminerscreenshot"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
RapidMiner tool
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:rminerscreenshot"

\end_inset


\end_layout

\begin_layout Plain Layout

\shape italic
A complete process is shown which consists of operators that import data
 from a CSV (Comma separated values) file, removes outliers, clusters the
 dataset, and writes the result to an output CSV file.
 On the right of the screen, we can modify RapidMiner's settings for k-means
 clustering.
 For example, we can set the value of k to the number of clusters we want.
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Data Sources
\end_layout

\begin_layout Standard
The initial step in the project involves collecting as much data as possible
 on various players.
 Since the project determines key traits of players, a large amount of data
 must be analysed to ensure accuracy of these key traits.
 There are a significant amount of online resources, such as websites like
 
\family typewriter
http://www.tennisinsight.com
\family default
, which provide a significant amount of detailed statistics of every professiona
l tennis match played since the site was inaugurated.
\end_layout

\begin_layout Standard
A feature has launched on the website TennisInsight called Player Traits,
 which lets users tag players with characteristic traits.
 In this project, based on statistics of players alone, we determine similar
 player traits.
 Furthermore, we look at the significance of each of these traits in the
 eventual outcome of the match.
\end_layout

\begin_layout Section
Obtaining data: Web scraping
\end_layout

\begin_layout Standard
The first part of the project consisted of obtaining the required data to
 analyse players and their characteristics.
 A significant amount of historical data needed to be collected and as mentioned
 previously, 
\family typewriter
www.tennisinsight.com
\family default
 and 
\family typewriter
www.atpworldtour.com
\family default
 proved to be a very useful source of data, with all required match statistics
 and player profile information.
 Unfortunately, the website does not have an API which made retrieving the
 data difficult.
 It was obviously impractical to obtain the data manually.
 Hence, a web scraper was developed using Scrapy, a Python web scraping
 framework, to obtain the relevant statistics from these websites.
\end_layout

\begin_layout Standard
The complete web scraper was made up of two separate scrapers, one to pull
 match statistics and one to retrieve the betting odds for a player to win
 the match.
 This was required because of the website's design, which had these two
 sets of information of different pages.
 TennisInsight identifies each player by a 'player id', which is used in
 the scraper as well.
 Both scrapers take this player id as an input to identify the corresponding
 tennis player and retrieve the player's data from his last 100 matches.
 The web scraper, although not the focus of this project, took a significant
 amount of time particularly due to my initial lack of knowledge on web
 scrapers, regular expressions, and xpaths, which were all used to a great
 extent to retrieve the data that was needed.
\end_layout

\begin_layout Subsection
Match Statistics Scraper
\end_layout

\begin_layout Standard
This is the first component of the web scraper.
 The scraped pages each contain a list of all of a player's matches with
 corresponding links to more detailed match statistics (which are on either
 the ATP's website or TennisInsight).
 We can see an excerpt of a scraped page, which contains a list of Roger
 Federer's matches, in Figure [figure reference].
 An example hyperlink to the match statistics is shown by the red box.
 
\end_layout

\begin_layout Standard
Example match statistics links are shown in Figure [figure reference to
 code].
 We can see that the TennisInsight website either points to an external
 page on the ATP website (atpworldtour.com) or points to a page on TennisInsight.
 Our scraper finds each of these links by using both regular expressions
 and xpaths.
 We use regular expressions to match the pattern of the links we want to
 open (see Figure [figure reference]), and xpaths to point to specific nodes
 on the HTML page.
 As an example, the URLs we wanted to open belonged to the xpath 
\begin_inset Formula $//td[@class="matchStyle"]$
\end_inset

, which means that the data had a 'td' tag and belonged to the 'matchStyle'
 class.
\end_layout

\begin_layout Standard
Our scraper opens each of these links, and parses the target webpage.
 These target web pages contain the statistics of each match, and are of
 the form shown in Figure [figure reference to matchstatspagesTI&atp].
 In this figure, on the left is an example of the Match Statistics page
 on the TennisInsight website, while on the right, we have an example of
 the Match Statistics page on the ATP website.
 Separate parsers were built for each of these two types of pages.
 These pages were parsed based on keywords on the page, such as 
\begin_inset Quotes eld
\end_inset

Tournament,
\begin_inset Quotes erd
\end_inset

 
\begin_inset Quotes eld
\end_inset

Aces,
\begin_inset Quotes erd
\end_inset

 etc.
 All match statistics are downloaded in a similar way for each player, saving
 them to a CSV (comma separated values) file.
 
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "basicstyle={\small\sffamily}"
inline false
status open

\begin_layout Plain Layout

Form of URLs wanted:
\end_layout

\begin_layout Plain Layout

javascript:makePopup('match_stats_popup.php?matchID=186134402')
\end_layout

\begin_layout Plain Layout

Regular Expression:
\end_layout

\begin_layout Plain Layout

match_stats_popup.php
\backslash
?matchID=
\backslash
d+
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Form of URLs wanted:
\end_layout

\begin_layout Plain Layout

javascript:makePopup('http://www.atpworldtour.com/
\end_layout

\begin_layout Plain Layout

	Share/Match-Facts-Pop-Up.aspx?t=416&y=2014&r=3&p=CA12')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

Regular Expression:
\end_layout

\begin_layout Plain Layout

http
\backslash
:
\backslash
/
\backslash
/www
\backslash
.atpworldtour
\backslash
.com
\backslash
/Share
\backslash
/Match
\backslash
-Facts
\backslash

\end_layout

\begin_layout Plain Layout

	-Pop
\backslash
-Up
\backslash
.aspx
\backslash
?t=
\backslash
d+&y=
\backslash
d+&r=
\backslash
d+&p=...."
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Odds Scraper
\end_layout

\begin_layout Standard
A second scraper was needed because the match statistics and the odds were
 on separate pages.
 The odds for a player to win were scraped and these were merged with the
 match statistics collected previously to create a complete record.
\end_layout

\begin_layout Standard
In addition, the dates for each of the matches played was on this page too,
 so the odds scraper retrieved this information as well.
 Like the Match Statistics Scraper described above, xpaths and regular expressio
ns were again used to find the required data.
 For example, the regular expression that matched odds of the form $1.212
 was 
\begin_inset Quotes eld
\end_inset


\backslash
$
\backslash
d+
\backslash
.
\backslash
d+
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsection
Linking scraped records from both scrapers
\end_layout

\begin_layout Standard
After this data was collected separately by two different scrapers, it was
 important for them to be linked together to form complete records to simplify
 processing at later stages in the project.
 SQLite, a SQL database engine was used for this purpose, providing a quick
 and straightforward way to join tables using standard SQL commands.
\end_layout

\begin_layout Section
Developing a model
\end_layout

\begin_layout Standard
There are often similar aspects and styles between two tennis players.
 For example, there are players who rely on their serves to win a majority
 of their points, while there are other players who are not particularly
 strong servers, but win a relatively higher percentage of points when returning.
 In addition, there are some players who perform above the market expectations
 when they play on their preferred tennis court surface.
\end_layout

\begin_layout Standard
In this project, we aim to capture various types of players by analysing
 a range of match statistics and player information and use this data to
 build a model to help us get an indication of the eventual winner of a
 tennis match.
 In the general sense, we can use this information to find out whether,
 in a match up between two players, a certain player with a particular playing
 style has an advantage over another player with another playing style.
 We use clustering techniques over our match statistics and player profiles
 to identify these different playing styles, and to classify 'similar' players
 into specific clusters.
\end_layout

\begin_layout Subsection
Similar players
\end_layout

\begin_layout Standard
In this project, we introduce the idea of players with similar profiles
 in our model.
 We focus on two sets of attributes to identify similar players: general
 player profiles and past opponent profiles.
 In this section, we will first look at the attributes that belong to each
 set, and then proceed to how we can use clustering to group players into
 categories using these attributes.
\end_layout

\begin_layout Standard
For this project, we focus our analysis on the top 30 ranked players on
 the ATP tour as of May 20th 2014 [reference put rank list in appendix].
 [change why chosen the top 30 players] In addition, we have also included
 three other players in our analysis: Jeremy Chardy (ranked 40), Lleyton
 Hewitt (ranked 44), and Andreas Seppi (ranked 33), since these three players
 introduce interesting aspects into the project.
 For example, Lleyton Hewitt was ranked as world number 1 in 2001/02, but
 is currently 44, while Jeremy Chardy has caused some significant upsets
 over the past two years.
\end_layout

\begin_layout Subsubsection
General player profiles
\end_layout

\begin_layout Standard
The first set of attributes that we use to identify similar players include
 players' general statistics over the year leading up to the match that
 needs to be predicted.
 Data for this was retrieved from the TennisInsight website, which had profile
 pages on every tennis player.
 The attributes that we have included in the clustering are:
\end_layout

\begin_layout Enumerate
Surfaces (statistics include all matches over the past year)
\end_layout

\begin_deeper
\begin_layout Enumerate
Hard court win percentage
\end_layout

\begin_layout Enumerate
Clay court win percentage
\end_layout

\begin_layout Enumerate
Grass court win percentage
\end_layout

\end_deeper
\begin_layout Enumerate
Height
\end_layout

\begin_layout Enumerate
Age
\end_layout

\begin_layout Enumerate
Average net approaches (over previous 100 games where data is available)
\end_layout

\begin_layout Enumerate
Average first serve speed (over previous 100 games where data is available)
\end_layout

\begin_layout Enumerate
Service points won percentage (past year) across all opponents
\end_layout

\begin_layout Enumerate
Return points won percentage (past year) across all opponents
\end_layout

\begin_layout Enumerate
End of year ranking
\end_layout

\begin_layout Enumerate
Win percentage against the Top 20 ranked players (past year)
\end_layout

\begin_layout Standard
These statistics were collected for each player and fed into a CSV (Comma-separa
ted values) file, which is used to perform clustering over in section [section
 reference].
 As we will see in more detail later, clustering takes all these eleven
 statistics and groups players with similar statistics.
 Each cluster refers to a set of 'similar' players, which is what we try
 to achieve in this section.
\end_layout

\begin_layout Standard
It was an important decision to select the above attributes.
 A player's age was used because, as in any sport, it is a significant character
istic in classifying players, as this statistic is likely to give us an
 indication of a player's court speed.
 Height is considered to be a particularly important characteristic in tennis,
 especially for servers, as it makes a player's service harder to return
 because of the power, height, and bounce that is generated from a serve
 [reference to http://edition.cnn.com/2012/10/15/sport/tennis/tennis-nishikori-jap
an-size/index.html].
 In tennis, many players are seen to have their 'favorite' tennis court
 surface, and we introduce their win rate on the three different major surfaces
 to take this into account.
 We have included the average first serve speed and net approaches to classify
 players who rely largely on their service and their approaches to the net
 (also known as 
\begin_inset Quotes eld
\end_inset

serve and volley players
\begin_inset Quotes erd
\end_inset

).
 The service and return points won percentages are useful indicators of
 a player's overall performance across all their opponents.
 We describe the importance of these two statistics in the background section[re
ference to Tennis Equations].
 The final two statistics, win percentage against the top 20 and the end
 of year ranking, encompass a large variety of different attributes in one
 statistic, as described next in Limitations.
\end_layout

\begin_layout Subsubsection*
Limitations
\end_layout

\begin_layout Standard
It is a challenge to capture different playing styles of players through
 simply match statistics, especially due to the limitations of the data
 available.
 For example, we are able to retrieve information about a player's percentage
 of points won, and his preferred surface.
 However, more in-depth player information such as whether or not a player
 relies on a strong forehand, a player's court speed, or the degree of top-spin
 used in shots would certainly be beneficial for identifying more accurate
 playing styles.
 We aim to minimise the influence of this data limitation by including 'generic'
 attributes, such as the player's performance versus the Top 20 (for the
 previous year) or their end of year ranking, into the clustering analysis.
 'Generic' attributes encompass a player's performance over several games,
 and is likely to include certain factors that cannot be measured individually.
 For example, Rafael Nadal's has won 80% of his last ten matches against
 the Top 20 over the past year (as of June 8 2014), while Jerzy Janowicz
 has won 20%.
 This clearly tells us first that Nadal is the stronger player, winning
 a higher majority of his matches against a higher ranked opposition.
 However, this 80% value also serves as a statistic which measures Nadal's
 overall performance in these particular games, likely to be indicating
 his performance in specific (often unmeasurable) factors such as more accurate
 shots and a better tactical performance against the Top 20 players.
 
\end_layout

\begin_layout Subsubsection*
Normalising Statistics
\end_layout

\begin_layout Standard
The above attributes are presented in a wide range of units.
 For example, height is in centimetres, age is in years, and first serve
 speed is in kilometres per hour.
 Especially for clustering techniques used later on in the project, it is
 very integral that data is normalised and that there is no bias.
 Clustering techniques used later [section reference] make use of a distance
 measure, particularly the Euclidean distance, and if data was not rescaled
 or normalized, there would be significant biases in the clusters.
 The reason for this is that the clusters are influenced strongly by the
 magnitudes of the variables, especially in clustering techniques like k-means.
\end_layout

\begin_layout Standard
The formula used to rescale each attribute to the range [0,1] is presented
 in equation [equation reference].
 It is also known as feature scaling.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
X_{new}=\frac{X-X_{min}}{X_{max}-X_{min}}
\]

\end_inset


\end_layout

\begin_layout Standard
The statistics that were normalised were height, age, average net approaches,
 end of year ranking, and average first serve speed.
 The other statistics are already percentages in the range of [0,1], so
 there is no need to rescale them.
 Since every attribute was in the same range, all attributes were given
 equal importance.
\end_layout

\begin_layout Subsubsection
Past opponent profiles
\end_layout

\begin_layout Standard
There is a significant limitation introduced if only general player profiles
 was used to classify similar players.
 The reason for this is that professional tennis players often approach
 their opponents in different ways, and not in the same way as statistics
 classify players.
 In addition, tennis players often perform better against a certain opponent
 A than another opponent B, even though both players A and B are similar
 statistically.
 This is why we also introduce 'past opponent profiles' to determine similar
 players.
 Essentially, this means that for a certain player, we look at the performances
 of each of his past opponents (in his last 100 matches) and group together
 opponents who perform similarly, in terms of service and return points
 won.
 Hence, the set of attributes used here to identify similar players includes
 just the percentage of service points won and the percentage of return
 points won.
\end_layout

\begin_layout Standard
Let us look at an example of the limitation introduced if solely the general
 player profiles were used to determine similar players, and how the concept
 of 'past opponent profiles' minimize this limitation.
 Roger Federer and Novak Djokovic are similar players in terms of general
 player profiles and statistics (both players have a consistent record against
 the top 20 players, have similar service and return points won percentages,
 and have similar heights and similar service speeds).
 However, let us look at these player's previous performances when playing
 current world number one Rafael Nadal.
 Roger Federer has lost each of his last five encounters against Nadal,
 while on the other hand, Novak Djokovic has won four out of his last five
 encounters with Nadal (statistics correct as of June 2014).
 This example gives us some indication that even though players might be
 very similar statistically (as in the case of Federer and Djokovic), their
 particular opponent is a key factor in determining the outcome of the tennis
 match.
\end_layout

\begin_layout Subsubsection*
Using Service & Return Points Won
\end_layout

\begin_layout Standard
As mentioned earlier, to create the past opponent profiles for a player,
 we analyze the player's past 100 matches against all opponents.
 Each match corresponds to an individual record; hence, if a player has
 played against a specific opponent multiple times, each encounter is represente
d as a separate record.
 For each of the past 100 matches, out of all match statistics, only the
 service points won and return points won percentages of each opponent are
 used for the next phase, which is the clustering phase.
 There are a few reasons that this decision was made.
 We have discussed in the background [section reference] the importance
 of the difference in service points and return points won percentages to
 the overall outcome of the tennis match.
 In fact, we later use only this difference in percentages to predict the
 probability of a player winning a match [section reference to 3].
 
\end_layout

\begin_layout Standard
It is important, however, to keep in mind specific cases where a player
 has won more points overall in a match, but has still lost the game.
 For instance, in the 2009 Australian Open Final between Roger Federer and
 Rafael Nadal, Federer won 174/347 points (50.14% of points) while Nadal
 won 173/347 points (49.85% of points), although Federer lost the match.
 Additionally, 
\shape italic
both
\shape default
 Nadal and Federer won 59% of their service points and 40% of their return
 points.
 However, cases like these are rare in tennis, and we can thus consider
 the service and return points won statistics to be good approximations
 for a large majority of tennis matches.
\end_layout

\begin_layout Standard
Other match statistics available that have been scraped using our web scraper
 include the number of aces in a match, break points won, break points saved,
 etc.
 However, this information wasn't used because they are not a good descriptor
 of overall match performance.
 For example, a player that relies on his fast service might have a lot
 of aces in a match, but this has little bearing on how well he performed
 overall in a match.
 In addition, statistics like aces and break points only count for a very
 small number of points relative to the entire match, and are poor indicators
 of an overall match.
 Service and return points 
\end_layout

\begin_layout Standard
A key advantage of looking at all of a specific player's matches is that
 the data is normalised between his different opponents.
 For example, one player's points won on serve percentage might be higher
 than that of another player's, but the reason might be because he has played
 weaker opponents.
 By later clustering based on a specific player's matches, we can ensure
 that the service and return points won percentages are normalised, as they
 are from matches against a specific opponent.
\end_layout

\begin_layout Standard
In our overall model, for a match up between player A and player B, we first
 look at all their previous encounters.
 We look at all the players that have performed similarly to B in terms
 of service points and return points won percentages.
 We get this group of players by using clustering techniques, such as k-means,
 which we describe in further detail later in section [Section reference
 to clustering techniques].
 This is the set of similar players that we use later in Section 2.2.1 [section
 reference to spw Si] to generate predictions.
\end_layout

\begin_layout Subsection
Clustering
\end_layout

\begin_layout Standard
In the last section, we looked at the various attributes that we use to
 describe players in both types of profiles.
 For example, in the past opponent profiles, we have used service and return
 points won percentages to characterise a player's performance.
 In addition, in the general player profiles, we have used a variety of
 different statistics including players' win rate on different courts and
 serve speed.
 In this section, we focus on how we use clustering to classify these player
 statistics and attributes into different clusters.
 
\end_layout

\begin_layout Subsubsection
Clustering the general player profiles 
\end_layout

\begin_layout Standard
To group the general player profiles, discussed in section [section reference],
 into clusters, we use the software, RapidMiner.
 As described in the Background [section reference], RapidMiner is a platform
 that provides a complete environment for machine learning and data mining.
 An image of how RapidMiner is used can be seen in Figure [figure reference].
 We design a process which:
\end_layout

\begin_layout Enumerate
Reads our CSV file: The CSV file that we read is just a list of players
 and their attributes, that we created in section [section reference]
\end_layout

\begin_layout Enumerate
Select attributes & Set roles for clustering: We select all the fields that
 need to be used in the clustering and their respective roles.
 For example, the role of the 'player name' field is a 'label', not an attribute
, since we do not want to cluster by the player names.
 We set the roles of all other fields to the 'attribute' target role, since
 we want it to be used in the overall clustering.
\end_layout

\begin_layout Enumerate
Clustering: We focus on the k-means algorithm, and we vary its parameters
 for different trials.
 The output of each of these algorithms are compared in Section [section
 reference]
\end_layout

\begin_layout Enumerate
Write CSV: This ends the process by appending a column to the input CSV
 file which contains the cluster that each player belongs to.
 This is the output file that is read by my Python program to find similar
 players.
\end_layout

\begin_layout Subsubsection*
Implementation in overall system
\end_layout

\begin_layout Standard
Python code has been developed to read the output CSV from RapidMiner and
 find players belonging to a particular cluster.
 An excerpt of RapidMiner's CSV output can be seen in Figure [figure reference].
 Python code is reproduced in Figure [figure reference]
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

def get_similar_profile_players(player2):
\end_layout

\begin_layout Plain Layout

	f = open("profiles_clustered.csv")
\end_layout

\begin_layout Plain Layout

	clustered_profiles = csv.DictReader(f)
\end_layout

\begin_layout Plain Layout

	for player in clustered_profiles: 		
\end_layout

\begin_layout Plain Layout

		if(player["player"]==player2:			
\end_layout

\begin_layout Plain Layout

			cluster = player["cluster"]
\end_layout

\begin_layout Plain Layout

		break
\end_layout

\begin_layout Plain Layout

	f.seek(0)
\end_layout

\begin_layout Plain Layout

	similar_players = [] 	
\end_layout

\begin_layout Plain Layout

	for player in profiles_clustered: 		
\end_layout

\begin_layout Plain Layout

		if player["cluster"]==cluster:
\end_layout

\begin_layout Plain Layout

			similar_players.append(player["player"]) 	
\end_layout

\begin_layout Plain Layout

	return similar_players
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In Figure [figure reference], we find similar players to 'player2', which
 is a string of the player's name.
 We first iterate through the RapidMiner's CSV output by opening the file
 and loading it into a Python dictionary list.
 We then find the cluster that the player belongs to by iterating through
 the file, and setting the 'cluster' variable when we find the required
 player's cluster.
 Once we find the required cluster, we iterate through the file once more
 to find players which share the same cluster, returning this list of players
 at the end of the function.
 It is useful to note that 'player2' itself is included in the list of similar
 players returned by the function, because we consider 'player2' to be similar
 to itself.
 The output list that is returned is used in Section 2.3.1 [section reference]
 to create predictions of tennis matches.
\end_layout

\begin_layout Subsubsection*
Clustering algorithms
\end_layout

\begin_layout Subsubsection*
k-means
\end_layout

\begin_layout Standard
The k-means algorithm was explained in the Background section [section reference
].
 The algorithm aims to partition a set of n observations into a k number
 of clusters.
 There are two important aspects that need to be considered when using this
 algorithm:
\end_layout

\begin_layout Enumerate

\series bold
Initialization
\series default
: The k-means algorithm is very sensitive to the order of the dataset.
 This is because the first step involves randomly selecting cluster centres
 or centroids.
 RapidMiner has a feature called 'Determine good start values' which we
 have made use of in the clustering.
 This feature determines the first k centroids using the K-Means++ heuristic
 described in Artur's and Vassillvitskii's 
\begin_inset Quotes eld
\end_inset

k-means++: The Advantages of Careful Seeding
\begin_inset Quotes erd
\end_inset

 [reference].
 This ensures that the results of the clustering is the same over repeated
 trials.
\end_layout

\begin_layout Enumerate

\series bold
Value of k:
\series default
 The k-means algorithm is considered to be an extremely simple and efficient
 algorithm.
 However, it involves knowing the value of k prior to the clustering.
 This value of k determines how many clusters there will be in the result.
 One straightforward rule of thumb sets the value of k to 
\begin_inset Formula $\approx\sqrt{n/2}$
\end_inset

 where n is the number of observations in the dataset.
 There are other more advanced methods such as analyzing the gap statistic,
 or using an information criterion approach.
 When choosing a value for k, it is important to keep in mind that in this
 project, this value of k is equal to the number of different playing styles.
 For example, we are analyzing a total of over 30 players and if we want
 to have approximately 6 players in each cluster (or playing style), we
 can select the value of k to be 5.
 The appropriate value of k varies based on the application.
 We tested a variety of different values of k to find which gave and present
 the plots next.
 We also try to find the optimal number of centroids (value of k) using
 X-Means, a clustering algorithm which extends the k-means approach and
 uses the Bayesian Information Criteria (BIC) to find the appropriate number
 of centroids.
\end_layout

\begin_layout Standard
DIAGRAMS TRYING MANY DIFFERENT K's, showing centroids clearly.
 think about doing graphs in excel if cant get the labels properly
\end_layout

\begin_layout Standard
one of the diagrams is x-means
\end_layout

\begin_layout Subsubsection*
k-medoids
\end_layout

\begin_layout Standard
As described in the background, the k-medoids algorithm is very similar
 to the k-means algorithm.
 The only difference is that k-medoids chooses actual datapoints as centres,
 instead of imaginary centroids as in k-means.
 In k-medoids we try classify a player according to a real data point i.e.
 a real player.
 Thus, we cluster players that match an exact existing type of player (centroid)
, unlike in k-means where we cluster the players that match an imaginary
 centroid.
 For completeness, we plot the clusters of k-medoids to investigate any
 further trends in Figures [figure reference in the appendix??].
 
\end_layout

\begin_layout Standard
--changing aroudn the distance measure
\end_layout

\begin_layout Subsubsection
Past opponent profile clustering
\end_layout

\begin_layout Standard
To recall, we create a separate past opponent profile for each player in
 our dataset.
 This profile consists of a player's past 100 matches, along with their
 opponent's serve and return points won percentages in each of these matches.
 Unlike the general profile clustering, we implement the clustering algorithm
 (k-means) in Python instead of RapidMiner to perform the clustering.
 The reason for this is that the general profile clustering only needs to
 be clustered once at the start, since the attributes of each player don't
 change from match to match.
 However, in this section, as we make a prediction for a match in a list
 of fixtures, we add that game to the a player's dataset.
 This has the significant advantage of clusters being constantly updated,
 since we iterative cluster the dataset adding new data from every game.
\end_layout

\begin_layout Standard
For the k-means clustering algorithm, we use the clustering library PyCluster
 and scientific toolkit SciPy.
 PyCluster provides its own implementation of the k-means algorithm and
 it is used in the following way:
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

def kmeans_cluster(past_opponent_records):
\end_layout

\begin_layout Plain Layout

	# create a new list serve_return with only serve 
\end_layout

\begin_layout Plain Layout

	# points (rec[0]) and return points won 
\end_layout

\begin_layout Plain Layout

	# (rec[1]) percentages
\end_layout

\begin_layout Plain Layout

	for rec in past_opponent_records:
\end_layout

\begin_layout Plain Layout

		serve_return.append([float(rec[0]),float(rec[1])])
\end_layout

\begin_layout Plain Layout

	# chooses appropriate k-value for k-means
\end_layout

\begin_layout Plain Layout

	k = get_k_value(serve_return)
\end_layout

\begin_layout Plain Layout

	labels,error,nfound=Pycluster.kcluster(scipy.array(serve_return), k)
\end_layout

\begin_layout Plain Layout

	return labels
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As we can see, this function takes the argument 'past_opponent_records',
 which is a list of records.
 Each record contains the opponent's name, odds for a player to win the
 match, the serve and return points won percentages, as well as additional
 match statistics.
 Since we only want to cluster according to the serve and return points
 won percentages, we create a new list which contains only the serve and
 return points won percentages.
 We then pass this list to Pycluster's kcluster function, which is the k-means
 algorithm, along with the specified value of k.
 Pycluster's kcluster function only accepts arrays, not lists, so we use
 the Scipy library to convert from a list to an array.
\end_layout

\begin_layout Standard
One of the function's return values is 'labels', a list of integers where
 each integer corresponds to a separate cluster.
 A straightforward example of the output of the Pycluster function is shown
 in Figure [figure reference].
 In Figure [figure reference], we input four service and return points won
 percentages, and provide a k-value of 2 i.e.
 2 clusters.
 The output is in the final line 
\begin_inset Quotes eld
\end_inset

clusters: [0 1 0 1]
\begin_inset Quotes erd
\end_inset

, and this simply means that the first and third set of values belong to
 cluster 0, while the remaining values belong to cluster 1.
\end_layout

\begin_layout Standard
We use the rule of thumb technique, 
\begin_inset Formula $k=\sqrt{n/2}$
\end_inset

, where n is the total number of records in the dataset, to set the number
 of clusters k, at every step of the clustering.
 Since we perform this clustering for close to 500 fixtures that we predict
 later in Section [section reference], we aim to minimize the computational
 overhead associated with the clustering by using this heuristic.
\end_layout

\begin_layout Subsubsection*
Data Preprocessing
\end_layout

\begin_layout Standard
Before our dataset (CSV file for each player containing a list of past 100
 matches and respective statistics) was ready for clustering, there was
 some preprocessing that was required to be done to ensure its accuracy.
 There were two key steps that were carried out - these are the removal
 of outliers and flagging specific data points.
\end_layout

\begin_layout Subsubsection*
Detection and removal of outliers
\end_layout

\begin_layout Standard
Outliers can be defined as observations that deviate significantly from
 other samples in the dataset, by lying at an 'abnormal' distance from other
 values.
 RapidMiner was again used in this data preprocessing step to remove these
 outliers in the datasets.
 
\end_layout

\begin_layout Standard
RapidMiner's operator, 
\begin_inset Quotes eld
\end_inset

Detect Outliers
\begin_inset Quotes erd
\end_inset

, implements an outlier detection approach outlined in 
\begin_inset Quotes eld
\end_inset

Efficient Algorithms for Mining Outliers from Large Data Sets
\begin_inset Quotes erd
\end_inset

 by Ramaswamy, Rastogi, and Shim [reference to this paper].
 The outlier detection approach is straightforward.
 Each point is ranked based on its Euclidean distance to its k-th nearest
 neighbour, and the top n ranked points in this ranking are detected as
 outliers.
 The values for k and n were provided, and this was chosen as 10 neighbours
 and 5 outliers respectively.
 This means that out of our dataset of approximately 100 matches for each
 player, 5 matches are detected as outliers (and hence, removed) based on
 their service points and return points won percentage.
 
\end_layout

\begin_layout Standard
The reason outliers were removed was because it was noticed that in certain
 matches scraped by our web scraper, matches either weren't played or were
 not completed leading to either values such as 0% for percentage of service
 and return points won, or very high unrealistic values (>90%) for percentage
 of service points won.
 TennisInsight (the website scraped) didn't have a filter to exclude these
 matches so 'flawed' data like this was still included in the original dataset,
 and initially skewed calculations and hence, match predictions greatly.
 After these outliers were removed, however, we obtained more realistic
 calculations.
 
\end_layout

\begin_layout Standard
In Figure [figure reference], we can see a screenshot of the RapidMiner
 process which includes the outlier detection and removal operators.
 This process was run for each player's dataset separately.
 We have instructed RapidMiner to 
\end_layout

\begin_layout Enumerate
Read CSV: Load the original dataset through the Read CSV operator
\end_layout

\begin_layout Enumerate
Set Role & Select Attributes: Set the role of and select attributes (Service
 points and return points won percentage) that we want to include for detecting
 outliers
\end_layout

\begin_layout Enumerate
Detect Outliers: RapidMiner detects outliers according to the method described
 earlier, adding a new boolean attribute 'outlier', which is set to True
 if the record is an outlier, or False if not.
\end_layout

\begin_layout Enumerate
Filter Examples: We filter out all records (referred to as examples in RapidMine
r) which have the attribute 'outlier' set to True.
 After this stage, all outliers have been successfully removed.
\end_layout

\begin_layout Enumerate
Write CSV: Write all the records which aren't outliers to a CSV file, which
 we use for the next stage (the clustering phase).
\end_layout

\begin_layout Standard
It is important to consider the possibility that there are some records
 that might be detected as outliers, which are in fact valid.
 However, the removal of five records out of one hundred for each player
 can be considered as insignificant, as it is only a very small portion
 of the complete dataset.
 The impact of the inclusion of five potentially erroneous records is significan
tly larger than the removal of five valid records (out of a dataset of 100).
\end_layout

\begin_layout Subsubsection*
Flagging Specific Records
\end_layout

\begin_layout Standard
Another step in the data preprocessing was removing specific matches from
 the dataset that might influence the overall dataset and eventual clusters
 and predictions.
 These include:
\end_layout

\begin_layout Enumerate
Matches where a player has been injured: If a player has either withdrawn
 or retired from a match due to injury, that record is removed from the
 dataset.
 Injury is an external factor that skews data and the eventual clusters
 significantly, since players usually perform worse than usual.
 Additionally, matches that have occurred up to 14 days after a reported
 injury are also not included in the dataset.
 This was done to ensure that after effects of injuries were also taken
 into account.
 
\end_layout

\begin_layout Enumerate
Exhibition and Davis Cup matches: These are matches which do not count towards
 a player's ATP points, or their professional ranking.
 Since they are not as 'important' as matches on the ATP tour, it is possible
 that players may underperform in matches like these, so they aren't included
 in the dataset.
\end_layout

\begin_layout Subsubsection*
Limitations
\end_layout

\begin_layout Standard
To obtain an accurate set of similar opponents using the past opponent profiles,
 it is preferable that players have played the same opponent more than once.
 If two players have played each other only once, the set of similar players
 obtained is completely based on that last encounter.
 Results become problematic if in that last encounter a player underperformed
 or overperformed, resulting in a surprise defeat or win.
 Fortunately, we have focused our analysis on players in the top 40; these
 players usually play in the same tournaments and often encounter each other
 more than once over the course of their last 100 matches.
 
\end_layout

\begin_layout Standard
If two players have played each other more than once and they performed
 differently on both occasions (performed differently in terms of service
 and return points won), it is likely that each record might be in different
 clusters i.e.
 the same player belongs to two different clusters.
 In this case, the set of similar players are players that are in either
 cluster.
 In the initial implementation of the model, if a player was in multiple
 different clusters, the average of the service and return points won in
 all these clusters was used, instead of taking all players in either cluster.
 However, this is likely to put a player in a cluster that he does not belong
 to at all.
 
\end_layout

\begin_layout Standard
Let's take the following example: In previous matches between player A and
 player B, player B's performances were the following:
\end_layout

\begin_layout Itemize
Match 1: Player B won 80% of service points, 30% of return points
\end_layout

\begin_layout Itemize
Match 2: Player B won 40% of service points, and 30% of return points
\end_layout

\begin_layout Standard
Let's assume Player B is a very good player and Match 1 represents the true
 performance of Player B, and Match 2 represents a game where he was unfit
 and played poorly.
 If the average of these performances were taken, Player B would be put
 into a cluster with other players who have a performance of 60% of service
 points won and 30% of service points won.
 Although this is an extreme case, this is something we want to avoid.
 Hence, we consider players in both clusters.
\end_layout

\begin_layout Subsubsection*
Summary so far
\end_layout

\begin_layout Standard
In this previous section, we use data that we scraped in Section [section
 ref] to generate both general player profiles for all players collectively
 and past opponent profiles for each opponent.
 The next stage is then the clustering phase.
 In this phase, we cluster player profiles with the RapidMiner tool, using
 the k-means algorithm and other variations of it, where we modify the value
 of k to generate a range of different player styles.
 We also cluster player opponent profiles for each player based on the proportio
n of serve and return points won in each player's past 100 matches using
 the k-means algorithm.
 To generate a set of similar players for player A, for example, we obtain
 all players in the same cluster as A in the general player profiles.
 In addition, in a match up between player A and player B, we look at their
 previous encounters, and find players that performed similarly to A in
 terms of serve and return points won across B's past 100 matches.
 These are the set of similar players to A, in a specific match up against
 B.
 The diagram in Figure [figure reference] represents the data flow so far.
\end_layout

\begin_layout Standard
INSERT DIAGRAM ON DATAFLOW HERE
\end_layout

\begin_layout Standard
In the next section, we introduce how we predict the outcome of a tennis
 match between two players, player A and player B.
 We use the generated sets of similar players for each player, and use each
 player's performance against their opponent's of similar players, to come
 up with a probability of each player winning the match.
\end_layout

\begin_layout Subsection
Difference in service points won
\end_layout

\begin_layout Standard
As mentioned earlier in the report, a key indicator of a player's performance
 in a tennis match depends on the percentage of points won on serve by each
 player.
 These point-winning probabilities have been used in most tennis models
 till date and are the key inputs to hierarchical Markov tennis models,
 which rely on these point winning probabilities to return a probability
 of a player winning a match.
 
\end_layout

\begin_layout Standard
O'Malley [reference] reasoned that it is the difference between the serve
 winning probabilities of each player that is integral to calculating a
 player's point winning probability and hence overall match winning probability.
 It is important to note that the actual values of the point winning probabiliti
es themselves are not as crucial as the relative difference between them.
\end_layout

\begin_layout Standard
The above findings have been used in recent tennis models, such as in the
 common opponent model proposed by Knottenbelt [reference], as well as in
 this project.
 In the common opponent model, the difference in service points won by each
 player is derived from each player's relative performance against common
 opponents.
 For example, to model how two players, player 
\shape italic
A
\shape default
 and player 
\shape italic
B
\shape default
, would play against each other, we look at the difference in service points
 won by 
\shape italic
A
\shape default
 and 
\shape italic
B
\shape default
 against a set of common opponents, 
\shape italic

\begin_inset Formula $C_{i}$
\end_inset


\shape default
's.
 We can then add the differences, which are either positive or negative,
 to the probability of winning a point on serve for each player in a match
 up between 
\shape italic
A
\shape default
 and 
\shape italic
B
\shape default
.
 The common opponent model takes advantage of the element of transitivity
 in tennis across particular i.e.
 if player A is better than a player C, and player C is better than player
 B, then player A is likely to be better than player B.
 However, this is not necessarily true, since players might have completely
 different styles and may perform better against certain types of players.
 This is a limitation that our proposed model addresses through the use
 of similar players.
 NOTE: COMMON OPP MODEL IS TRANSITIVITY OVER PARTICULAR PLAYERS, WHILE MY
 MODEL IS OVER SETS OF PLAYERS SO MORE ACCURATE
\end_layout

\begin_layout Subsubsection
Formulas and Implementation
\end_layout

\begin_layout Standard
We incorporate the ideas of similar players discussed previously into the
 difference in service points won method.
 Instead of common opponents like in the common opponent model, we use similar
 opponents through player profiles.
 
\end_layout

\begin_layout Standard
In a match between player A and B as before, we instead look first at the
 difference in the percentage of service points won between A and a set
 of 'similar' opponents to B.
 We then look at the difference in the percentage service points won between
 B and a set of 'similar' opponents to A.
 These differences correspond to the advantage player A has over player
 B and the advantage player B has over player A, respectively.
 Either of these advantages can be negative, which will represent a disadvantage
 for a player over another.
 
\end_layout

\begin_layout Standard
The below formulas describe how each is calculated.
 These formulas are very similar to what has been presented by Knottenbelt
 [reference], except that instead of common opponents
\begin_inset Formula $C_{i}$
\end_inset

, we use similar opponents
\begin_inset Formula $S_{i}$
\end_inset

.
\end_layout

\begin_layout Standard
For each similar opponent, 
\begin_inset Formula $S_{i}$
\end_inset

, we calculate 
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

, which is the measure of the advantage Player A has over Player B in terms
 of the percentage of service points won.
 Note that spw(X,Y) is the percentage of points won on serve by Player X
 against Player Y, while rpw(X,Y) is the percentage of points won on return
 by Player X against Y:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\triangle_{i}^{AB}=(spw(A,S_{i})-(1-rpw(A,S_{i})))-(spw(B,S_{i})-(1-rpw(B,S_{i})))
\]

\end_inset


\end_layout

\begin_layout Standard
To model a game between player A and B, we can influence the probability
 of winning a point on serve by adding the value of
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

to player A's probability of winning a point on serve, and subtracting the
 value of
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

from player B's probability of winning a point on serve.
 This is done in the following way:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(A\, beats\, B)\approx\frac{M_{3}(0.6+\triangle_{i}^{AB},\,(1-0.6))+M_{3}(0.6,\,1-(0.6-\triangle_{i}^{AB}))}{2}
\]

\end_inset


\end_layout

\begin_layout Standard
The function 
\begin_inset Formula $M_{3}(p,q)$
\end_inset

 was proposed by O'Malley [reference], and was introduced earlier in the
 background section [section reference].
 It takes as inputs p, which is the probability of player A winning a point
 on his serve, and q, which is the probability of player B winning a point
 on his serve, and outputs a probability of player A beating B in a three
 set match using a hierarchical model.
 For a five set match, we use
\begin_inset Formula $M_{5}(p,q)$
\end_inset

 instead of 
\begin_inset Formula $M_{3}(p,q)$
\end_inset

.
 We revisit O'Malley's formulae in section 3.2 [Reference].
 In equation [equation reference], we take the average of the two match
 winning probabilities calculated.
 
\end_layout

\begin_layout Standard
As with the rest of the project, Python was used to implement the above
 logic.
 Figure [code reference] presents the implementation of how 
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

 is calculated.
 This is calculated for each player in every game.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

# Arguments: 
\end_layout

\begin_layout Plain Layout

# 'player_list' is past opponent (profile) list of the 
\end_layout

\begin_layout Plain Layout

# player until the game we are prediction.
 This ensures 
\end_layout

\begin_layout Plain Layout

# that we don't use future data
\end_layout

\begin_layout Plain Layout

# 'opponent' is the opponent of the current player.
 This is # player 'B' in the formulas described
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

def calculate_spw_difference(player_list,opponent):
\end_layout

\begin_layout Plain Layout

	# this function obtains players similar to the opponent
\end_layout

\begin_layout Plain Layout

	# according to the General Player Profiles
\end_layout

\begin_layout Plain Layout

	players_in_p2_profile=get_similar_profile_players(opponent)
\end_layout

\begin_layout Plain Layout

	normalisation_counter, difference_a_c, counter = 0, 0, 0
\end_layout

\begin_layout Plain Layout

	# this function returns a list of size player_list,
\end_layout

\begin_layout Plain Layout

	# where each element i in cluster_labels represents 
\end_layout

\begin_layout Plain Layout

	# the cluster that element i in player_list belongs to
\end_layout

\begin_layout Plain Layout

	cluster_labels = cluster.kmeans_cluster(player_list)
\end_layout

\begin_layout Plain Layout

	# cluster_list contains all the clusters that the
\end_layout

\begin_layout Plain Layout

	# opponent is similar to.
 We use the counter variable to
\end_layout

\begin_layout Plain Layout

	# keep track of the position in cluster_labels
\end_layout

\begin_layout Plain Layout

	for rec in player_list:
\end_layout

\begin_layout Plain Layout

		if opponent==rec[2]:
\end_layout

\begin_layout Plain Layout

			cluster_list.append(cluster_labels[counter])
\end_layout

\begin_layout Plain Layout

		counter+=1
\end_layout

\begin_layout Plain Layout

	for rec in player_list:
\end_layout

\begin_layout Plain Layout

		same_profile = 0 
\end_layout

\begin_layout Plain Layout

		# rec[2] refers to the opponent in the current record.
\end_layout

\begin_layout Plain Layout

		# Set same_profile = 1 if any of those players are
\end_layout

\begin_layout Plain Layout

		# similar to the initial opponent in terms 
\end_layout

\begin_layout Plain Layout

		# of General Player Profiles
\end_layout

\begin_layout Plain Layout

		if any(x in rec[2] for x in players_in_p2_profile): 			same_profile =
 1
\end_layout

\begin_layout Plain Layout

		# if the current record is in any of the 
\end_layout

\begin_layout Plain Layout

		# same clusters in cluster_list, or the player 
\end_layout

\begin_layout Plain Layout

		# is in the same general player profiles 
\end_layout

\begin_layout Plain Layout

		# cluster, continue with the spw 
\end_layout

\begin_layout Plain Layout

		# difference calculation
\end_layout

\begin_layout Plain Layout

		if (cluster_labels[cluster_labels_counter] in cluster_list) or same_profile:
\end_layout

\begin_layout Plain Layout

			# get the required service and return points 
\end_layout

\begin_layout Plain Layout

			# won percentages
\end_layout

\begin_layout Plain Layout

			spw_p2 = float(rec[0]) 			
\end_layout

\begin_layout Plain Layout

			rpw_p2 = float(rec[1]) 
\end_layout

\begin_layout Plain Layout

			# this formula is identical to triangle_A_B.
\end_layout

\begin_layout Plain Layout

			# it was divided by 100 because the spw and rpw
\end_layout

\begin_layout Plain Layout

			# values were from 0 to 100, rather than from 0 
\end_layout

\begin_layout Plain Layout

			# to 1
\end_layout

\begin_layout Plain Layout

			difference_spw_rpw_p1 = (100.0-rpw_p2-spw_p2)/100
\end_layout

\begin_layout Plain Layout

			difference_a_c += difference_spw_rpw_p1
\end_layout

\begin_layout Plain Layout

			normalisation_counter+=1
\end_layout

\begin_layout Plain Layout

		cluster_labels_counter+=1
\end_layout

\begin_layout Plain Layout

	return (difference_a_c, normalisation_counter)
\end_layout

\end_inset


\end_layout

\begin_layout Section
Estimating a player's match winning probability
\end_layout

\begin_layout Standard
The calculation of a player's match winning probability is a key aspect
 of this project.
 In the previous section, we discussed how to calculate 
\begin_inset Formula $\triangle_{i}^{AB}$
\end_inset

, which is the value that represents the advantage or disadvantage that
 a player A has over player B in terms of the proportion of service points
 won against opponent Si.
 We use this value to influence the probability of winning a point on serve
 for each player in a match between player A and player B.
 Using this player's probability of winning a point on serve, we calculate
 the overall probability of a player winning a match.
\end_layout

\begin_layout Standard
O'Malley [reference] and Barnett [reference] have proposed hierarchical
 models of computing the game, set, and match winning probabilities using
 only the probabilities of a player winning a point on serve and on return.
 Both of these methods have been briefly discussed in the background section
 of the report.
 There are key differences between these two models.
 Barnett's model is implemented through a hierarchical Markov model, using
 recursive formulae to derive the probabilities of winning a game, set,
 and hence, match from any state (these states refer to particular game
 scores).
 On the other hand, O'Malley's model consists of equations which take the
 binary event of a player winning a point as a Bernoulli random variable.
 For this project, we have implemented O'Malley's model to calculate the
 match winning probability because we wanted to avoid the computational
 overhead of recursive methods, which are significant in this project, where
 we later predict a set of several hundred tennis matches.
 It is important to note, however, that the approach used in this project
 can be also used easily Barnett's model, as well as any other hierarchical
 model which takes as input the probabilities of a player winning a point
 on serve and return.
\end_layout

\begin_layout Subsection
Assumptions
\end_layout

\begin_layout Standard
A key assumption that both of these aforementioned models (Barnett's and
 O'Malley's) take into account is that each point is independently and identical
ly distributed (iid).
 This assumption was briefly touched upon in the background section of this
 project report [reference to section chapter].
 This iid assumption is that the probability of a player winning a point
 is independent of the outcome of the previous point(s) and it remains constant
 throughout the entire match.
 This is why both of the above models can be modeled as hierarchical models
 that take only the service points and return points won percentages of
 a player as inputs.
 It is intuitively difficult to accept that this assumption, especially
 considering several common phenomena that exist in sport such as fatigue
 and psychological momentum.
 For example, it is not unlikely that a player wins less points on his serve
 as the match progress due to fatigue and exhaustion.
 In addition, a player's momentum is considered by many to play a crucial
 role in the outcome of individual points.
\end_layout

\begin_layout Standard
This assumption was analyzed by Klaasen and Magnus [1].
 They tested the iid assumption using point to point data on four years
 of Wimbledon men's and women's singles matches.
 They reasoned that points are neither 
\shape italic
exactly
\shape default
 independently nor identically distributed.
 In other words, a player winning the previous point had a positive impact
 on a player winning the next point.
 However, most importantly, they found that deviations from the iid assumption
 were small and hence, this iid assumption can still be considered to be
 a good approximation.
 There are further useful observations that were presented in the same paper
 by Klaasen and Magnus: firstly, they observed that deviations change based
 on the 'importance' of points.
 Secondly, they found that the weaker the player, the stronger are the effects
 of these deviations.
 This is an additional reason for why we have focused our study on the top
 ranked players, to aim to minimise deviations from the iid assumption.
\end_layout

\begin_layout Subsection
Implementation
\end_layout

\begin_layout Subsubsection
Implementation of Formulas
\end_layout

\begin_layout Standard
We have implemented O'Malley's key formulas for each stage of the hierarchical
 model in Python.
 Using point level statistics (probability of each player winning a point
 on his serve), we can calculate the probability of a player winning a game
 and a tiebreaker game.
 We then use these calculated probabilities to derive the probability of
 a player winning a set and also hence winning the match.
 As an example, the formulas for the game level and three or five set match
 level of the hierarchy are revisited below.
 All formulas have been presented in the Background [reference].
\end_layout

\begin_layout Subsubsection*
Game Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
G(p)=P(player\, wins\, game)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\sum_{i=0}^{\infty}P(player\, wins\, game\, losing\, i\, points)
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}+4p^{4}(1-p)+10p^{4}(1-p)^{2}+20p^{3}(1-p)^{3}\centerdot\sum_{i=3}^{\infty}\{2p(1-p)\}^{i-3}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=p^{4}(15-4p-\frac{10p^{2}}{1-2p(1-p)})
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p$
\end_inset

 refers to the probability of a player winning a point on serve
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

The formula in Equation [equation reference] covers each case for a player
 to win a game on his serve.
 He can either win four straight service points, win four points to win
 a game while losing one or two points during the game, and finally the
 case for 30-30/Deuce.
 In the Deuce case, the number of points played until the server wins follows
 a geometric distribution since the game can in theory go on for an infinity
 amount of points.
\end_layout

\begin_layout Subsubsection*
Set Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
S(p,q)=\sum_{i=1}^{21}B(i,1)G(p)^{B(i,2)}(1-G(p))^{B(i,3)}G(q)^{B(i,4)}(1-G(q))^{B(i,,5)}
\]

\end_inset


\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
\qquad\:\times(G(p)G(q)+(G(p)(1-G(q))+(1-G(p))G(q))T(p,q))^{B(i,6)}
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $p,q$
\end_inset

 refers to the probability of each player winning a point on serve
\end_layout

\begin_layout Standard
\begin_inset Formula $T(p,q)$
\end_inset

 refers to the probability of a player winning a tiebreaker game
\end_layout

\begin_layout Standard
\begin_inset Formula $B(x,y)$
\end_inset

 refers to the coefficient matrix calculated by O'Malley.
\end_layout

\begin_layout Standard
The formula in Equation [equation reference] sums up the probabilities of
 all 21 game scores combinations in a set.
 
\begin_inset Formula $S(p,q)$
\end_inset

 is derived from the probabilities of each player winning a game (
\begin_inset Formula $G(p)$
\end_inset

 and
\begin_inset Formula $G(q)$
\end_inset

 ) and the probability of winning a tiebreaker, 
\begin_inset Formula $T(p,q)$
\end_inset

.
 The probability formula for the tiebreaker game has been described in the
 Background [section reference].
 To implement the definition of the matrix B(x,y), the Python library 'Numpy'
 was used, which provided increased readability versus an implementation
 using a list of lists.
 This matrix is presented in the appendix [reference].
\end_layout

\begin_layout Subsubsection*
Match Level
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{3}(p,q)=S(p,q)^{2}[1+2(1-S(p,q))]
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
M_{5}(p,q)=S(p,q)^{3}[1+3(1-S(p,q))+6(1-S(p,q))^{2}]
\]

\end_inset


\end_layout

\begin_layout Standard
The formula in Equation [equation reference] are for best of 3 matches and
 best of 5 matches respectively.
 For Grand Slam matches, the second formula was used, since all Grand Slam
 matches are best of five set encounters.
 For other matches on the ATP tour, the best of three set formula was used.
\end_layout

\begin_layout Subsubsection
Python code
\end_layout

\begin_layout Standard
To predict a specific match up between two players, player A and player
 B, the Python code presented in Figure [fig reference] is used.
 Note that this is not the complete function; user input methods have been
 removed for increased readability.
 Comments have been included to explain relevant parts of the code.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

# Arguments: 
\end_layout

\begin_layout Plain Layout

# player1 and player2 are the names of the two players
\end_layout

\begin_layout Plain Layout

def match_up(player1, player2): 	
\end_layout

\begin_layout Plain Layout

	spw_p1, counter_p1 = predictions(player1,player2)
\end_layout

\begin_layout Plain Layout

	spw_p2, counter_p2 = predictions(player2,player1)
\end_layout

\begin_layout Plain Layout

	# normalizing values 	
\end_layout

\begin_layout Plain Layout

	avg_p1spw = spw_p1/counter_p1 	
\end_layout

\begin_layout Plain Layout

	avg_p2spw = spw_p2/counter_p2 	
\end_layout

\begin_layout Plain Layout

	delta_a_b = avg_p1spw - avg_p2spw 	
\end_layout

\begin_layout Plain Layout

	# user inputs whether it is a five set or three set match
\end_layout

\begin_layout Plain Layout

	if (five_setter):
\end_layout

\begin_layout Plain Layout

		p1_win_probability = prediction.match_win_probability_5(0.6+delta_a_b,(1-0.6))
 + prediction.match_win_probability_5(0.6,(1-(0.6-delta_a_b)))
\end_layout

\begin_layout Plain Layout

	else:
\end_layout

\begin_layout Plain Layout

		p1_win_probability = prediction.match_win_probability_3(0.6+delta_a_b,(1-0.6))
 + prediction.match_win_probability_3(0.6,(1-(0.6-delta_a_b)))
\end_layout

\begin_layout Plain Layout

	# p1_win_probability refers to the probability that 
\end_layout

\begin_layout Plain Layout

	# p1 will win the match according to the model
\end_layout

\begin_layout Plain Layout

	p1_win_probability = p1_win_probability/2
\end_layout

\begin_layout Plain Layout

	p2_win_probability = 1-p1_win_probability
\end_layout

\begin_layout Plain Layout

	# predicted_odds_p1 indicates the predicted 
\end_layout

\begin_layout Plain Layout

	# odds according to the model.
 one should bet 
\end_layout

\begin_layout Plain Layout

	# only if market odds are greater than predicted odds
\end_layout

\begin_layout Plain Layout

	predicted_odds_p1 = 1/p1_win_probability
\end_layout

\begin_layout Plain Layout

	predicted_odds_p2 = 1/p2_win_probability
\end_layout

\end_inset


\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
In this project, a model was developed to predict the probability of a player
 winning a tennis match, using the idea of similar players through clustering
 techniques.
 There are three key aspects to consider to evaluate the project as a whole:
\end_layout

\begin_layout Enumerate

\shape italic
Evaluating the predictive model:
\shape default
 First and most importantly, we want to investigate the successfulness of
 our tennis prediction model.
 We aim to find out its successfulness when put into competition with bookmakers.
\end_layout

\begin_layout Enumerate

\shape italic
Evaluating the correctness of the implementation
\shape default
: We need to ensure that
\end_layout

\begin_deeper
\begin_layout Enumerate
The data collected in Section [section reference] from websites such as
 TennisInsight and ATP World Tour have been scraped correctly.
 
\end_layout

\begin_layout Enumerate
O'Malley's hierarchical equations described in Section [section reference]
 ,for calculating the probability of winning have been implemented correctly
\end_layout

\begin_layout Enumerate
Clustering functions, including the use of the Python clustering library
 Pycluster as described in Section [section reference], are used and implemented
 in the right way
\end_layout

\end_deeper
\begin_layout Enumerate

\shape italic
Evaluating the effectiveness of clustering algorithms
\shape default
 in determining a variation of player styles: We want to find out if the
 different clusters generated from the general player profiles are representativ
e of actual tennis playing styles.
 
\end_layout

\begin_layout Subsection
Evaluating the predictive tennis model
\end_layout

\begin_layout Subsubsection
Return on Investment
\end_layout

\begin_layout Standard
It is integral to evaluate the performance of our model in terms of the
 predictions it generates for tennis matches.
 We use past matches that we already know the winners of, to evaluate its
 successfulness.
 We have run our predictive model over a set of approximately 500 singles
 fixtures that have happened previously (from the start of 2013 to May 2014),
 and find the return on investment (ROI) generated when the model is put
 into competition with the actual betting market.
 This list of fixtures was generated by going through our entire dataset
 of all players' fixtures, and selecting the matches that involved players
 that were in our selected focused set of 33 players.
 Hence, these fixtures include only the set of all the matches where both
 players are in our set of 33 players.
 
\end_layout

\begin_layout Standard
For each of these matches/fixtures, we calculate the match winning probability
 for each player, and hence, using the formula 
\begin_inset Formula $predicted\: odds=1/predicted\: probability$
\end_inset

, we calculate the predicted odds for each player winning the tennis match.
 If the actual market odds are better than the predicted odds calculated
 for either player, we bet a fixed single unit (£1) on that player to win
 the match.
 We decided to use a fixed unit to ensure that our model follows a simple
 strategy and is consistent over a range of matches.
 Maximizing the ROI is not the key aim of our project.
 However, there is certainly scope to improve the return of investment by
 introducing a confidence or risk associated with each bet, decreasing the
 amount bet on a single match if there is a high risk.
 
\end_layout

\begin_layout Standard
Once we use our model to generate predictions of the outcomes of all fixtures,
 we find the eventual return on investment adding the total money won or
 lost for each bet.
 This allows us the significant advantage of being able to judge to what
 extent our model is successful when put to use in the real market.
 Python code is presented in Figure [figure reference], which shows how
 the described strategy is implemented.
 Note that the entire function is not shown, due to its lengthy implementation,
 and only relevant parts are presented.
\end_layout

\begin_layout Standard
\begin_inset listings
lstparams "breaklines=true,language=Python,numbers=left,showstringspaces=false,stepnumber=1"
inline false
status open

\begin_layout Plain Layout

def simulate_bets():
\end_layout

\begin_layout Plain Layout

	fixtures = csv.DictReader(open("fixtures.csv"))
\end_layout

\begin_layout Plain Layout

	roi = 0
\end_layout

\begin_layout Plain Layout

	# '...' refers to code to generate market and 
\end_layout

\begin_layout Plain Layout

	# predicted odds for each player.
 This code has
\end_layout

\begin_layout Plain Layout

	# been described in previous sections
\end_layout

\begin_layout Plain Layout

	...
 
\end_layout

\begin_layout Plain Layout

	for fixture in fixtures:
\end_layout

\begin_layout Plain Layout

		# winner is set to 1 if player 1 won the match,
\end_layout

\begin_layout Plain Layout

		# and set to 2 if player 2 won the match
\end_layout

\begin_layout Plain Layout

		winner = get_winner_of_fixture(fixture)
\end_layout

\begin_layout Plain Layout

		if (market_odds_p1>predicted_odds_p1):
\end_layout

\begin_layout Plain Layout

			# Bet on player 1 if the actual market odds 
\end_layout

\begin_layout Plain Layout

			# are better than the calculated predicted
\end_layout

\begin_layout Plain Layout

			# odds
\end_layout

\begin_layout Plain Layout

			betted = 1
\end_layout

\begin_layout Plain Layout

		elif (market_odds_p2>predicted_odds_p2):
\end_layout

\begin_layout Plain Layout

			# Bet on player 2
\end_layout

\begin_layout Plain Layout

			betted = 2
\end_layout

\begin_layout Plain Layout

		if (betted==1 and winner==1):
\end_layout

\begin_layout Plain Layout

			# if bet on player 1 and player 1 won the match
\end_layout

\begin_layout Plain Layout

			# add the profit to the overall roi
\end_layout

\begin_layout Plain Layout

			roi+=(market_odds_p1 - 1)
\end_layout

\begin_layout Plain Layout

		elif (betted==2 and winner==2): 
\end_layout

\begin_layout Plain Layout

			roi+=(market_odds_p2 - 1)
\end_layout

\begin_layout Plain Layout

		elif (betted!=winner):
\end_layout

\begin_layout Plain Layout

			# if bet incorrectly, subtract 1 pound from
\end_layout

\begin_layout Plain Layout

			# the overall roi
\end_layout

\begin_layout Plain Layout

			roi-=1
\end_layout

\begin_layout Plain Layout

	return roi
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To demonstrate this method on a specific example, we take the match played
 between Tommy Haas and Mikhail Youzhny in the Round of 32 of the US Open
 on September 2nd 2013.
 Using our model, we calculate predicted odds as 2.230 and 1.769 for each
 player, respectively.
 The market odds for that same match were 1.527 and 2.762, respectively, making
 Tommy Haas the clear favorite.
 As we can see, the market odds for Youzhny were higher than the predicted
 odds from our model 
\begin_inset Formula $(2.762>1.769)$
\end_inset

.
 Hence, we bet one pound on Youzhny in our simulation.
 Youzhny was the eventual winner, so we add the profit of £1.762 (
\begin_inset Formula $2.762-1)$
\end_inset

 to the overall return of investment.
\end_layout

\begin_layout Subsubsection
Results
\end_layout

\begin_layout Standard
After using the method described in the previous section, we arrive at the
 return of investment for our set of fixtures.
 The table of results can be seen in Table 1 [table reference].
 We have split our findings by surface, to investigate how our ROI results
 vary based on the court surface.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Surface
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Bets Made
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Binary Success Rate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Profit (£)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Return on Investment
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Hard Court
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
170
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
61.76%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17.037
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10.02%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Grass Court
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
70.59%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4.937
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
29.04%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Clay Court
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
86
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
62.79%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.144
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-1.33%
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Overall
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
273
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
62.64%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
20.83
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7.63%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Results obtained for fixtures involving our selected set of the top 33 players
 from January 2013 to May 2014
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The results above are certainly very interesting.
 Over the 273 bets made, with one pound bet on the predicted winner for
 each match, the return of investment calculated was 7.63%.
 The positive return is certainly an indication of the successfulness of
 the model.
 It is important to keep in mind that although the return on investment
 of Grass court matches was significantly higher than that of hard and clay
 courts, there was a significantly fewer amount of bets made on matches.
 The binary success rate (choosing the correct winner) is above 61% on all
 courts, and is 62.64% overall, indicating a promising success rate using
 the technique of similar players found through clustering.
 Detailed results for each of the bets placed are available in Appendix
 [appendix reference].
\end_layout

\begin_layout Standard
It is also very important to recognize the fact that in our model, we only
 have predicted fixtures which included the top ranked players playing against
 each other (as discussed before, we focused our analysis on a specific
 set of 33 players, which included the set of top 30 ranked players).
 Unlike other models, there were significantly fewer games in our predicted
 fixtures which included very strong favorites.
 For example, in other models, there are several matches which might include
 a top ranked player versus a wildcard to the tournament, which are significantl
y 'easier' to predict than an encounter between two players in the top 30.
\end_layout

\begin_layout Standard
It is important to note that there were only 273 bets made overall.
 This number is less than the total number of fixtures for two reasons:
\end_layout

\begin_layout Enumerate

\shape italic
Not enough similar players:
\shape default
 When the total number of similar players was less than or equal to 1 for
 either player, the fixture was not bet on.
 For example, if in a match up between player A and B, if player A hasn't
 played B before in our dataset and player A hasn't played against similar
 players to B according to general player profiles, then the total number
 of similar players is equal to zero, and hence, we cannot perform our method
 of using the difference in service and return points won against similar
 players.
 We also choose not to bet on matches where there is only one similar player,
 to avoid the significant amount of bias on that single match.
 
\end_layout

\begin_layout Enumerate

\shape italic
Market odds are too poor:
\shape default
 When the predicted odds (for the predicted winner) are less than the market
 odds we do not bet on a match.
\end_layout

\begin_layout Subsubsection
Comparison to other models
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard
It is also very important to recognize the fact that only matches amongst
 the top ranked players were analysed, since these were the selected players
 in our dataset.
 Unlike other models, games which included very strong favorites were not
 taken into account.
\end_layout

\begin_layout Standard
common opponent - higher ROI in ours but smaller and most importantly a
 different dataset used.
 this dataset was 2014.
 Comparable results show that this method should be pursued further.
 smaller success rate but with good reason - only focus on the top 30 players.
 very strong against each other so much higher likelihood of upsets
\end_layout

\begin_layout Standard
betting on favorite - 
\end_layout

\begin_layout Section
Appendix
\end_layout

\begin_layout Subsection*
A: Coefficient Matrices Used in O'Malley's Tennis Formulae
\end_layout

\begin_layout Subsubsection*
A.1: Table A
\end_layout

\begin_layout Standard
Table A was used in the tiebreaker tennis formula 
\begin_inset Formula $TB(p,q)$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing other 1.8
\begin_inset Formula $A=\left(\begin{array}{cccccc}
1 & 3 & 0 & 4 & 0 & 0\\
3 & 3 & 1 & 4 & 0 & 0\\
4 & 4 & 0 & 3 & 1 & 0\\
6 & 3 & 2 & 4 & 0 & 0\\
16 & 4 & 1 & 3 & 1 & 0\\
6 & 5 & 0 & 2 & 2 & 0\\
10 & 2 & 3 & 5 & 0 & 0\\
40 & 3 & 2 & 4 & 1 & 0\\
30 & 4 & 1 & 3 & 2 & 0\\
4 & 5 & 0 & 2 & 3 & 0\\
5 & 1 & 4 & 6 & 0 & 0\\
50 & 2 & 3 & 5 & 1 & 0\\
100 & 3 & 2 & 4 & 2 & 0\\
50 & 4 & 1 & 3 & 3 & 0\\
5 & 5 & 0 & 2 & 4 & 0\\
1 & 1 & 5 & 6 & 0 & 0\\
30 & 2 & 4 & 5 & 1 & 0\\
150 & 3 & 3 & 4 & 2 & 0\\
200 & 4 & 2 & 3 & 3 & 0\\
75 & 5 & 1 & 2 & 4 & 0\\
6 & 6 & 0 & 1 & 5 & 0\\
1 & 0 & 6 & 6 & 0 & 1\\
36 & 1 & 5 & 5 & 1 & 1\\
225 & 2 & 4 & 4 & 2 & 1\\
400 & 3 & 3 & 3 & 3 & 1\\
225 & 4 & 2 & 2 & 4 & 1\\
36 & 5 & 1 & 1 & 5 & 1\\
1 & 6 & 0 & 0 & 6 & 1
\end{array}\right)$
\end_inset


\end_layout

\begin_layout Subsubsection*
A.2: Table B
\end_layout

\begin_layout Standard
Table B was used in the set winning probability 
\begin_inset Formula $S(p,q)$
\end_inset

.
\end_layout

\begin_layout Standard
\paragraph_spacing other 1.8
\begin_inset Formula $B=\left(\begin{array}{cccccc}
1 & 3 & 0 & 3 & 0 & 0\\
3 & 3 & 1 & 3 & 0 & 0\\
3 & 4 & 0 & 2 & 1 & 0\\
6 & 2 & 2 & 4 & 0 & 0\\
12 & 3 & 1 & 3 & 1 & 0\\
3 & 4 & 0 & 2 & 2 & 0\\
4 & 2 & 3 & 4 & 0 & 0\\
24 & 3 & 2 & 3 & 1 & 0\\
24 & 4 & 1 & 2 & 2 & 0\\
4 & 5 & 0 & 1 & 3 & 0\\
5 & 1 & 4 & 5 & 0 & 0\\
40 & 2 & 3 & 4 & 1 & 0\\
60 & 3 & 2 & 3 & 2 & 0\\
20 & 4 & 1 & 2 & 3 & 0\\
1 & 5 & 0 & 1 & 4 & 0\\
1 & 0 & 5 & 5 & 0 & 1\\
25 & 1 & 4 & 4 & 1 & 1\\
100 & 2 & 3 & 3 & 2 & 1\\
100 & 3 & 2 & 2 & 3 & 1\\
25 & 4 & 1 & 1 & 4 & 1\\
1 & 5 & 0 & 0 & 5 & 1
\end{array}\right)$
\end_inset


\end_layout

\end_body
\end_document
